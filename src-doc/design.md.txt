% Tag-driven routing in a distributed storage network
% Ximin Luo

# Meta

## Terminology

arc
:	a directed relation $e = (v_s, v_t)$ from node $v_s$ to node $v_t$.
document
:	a storage object that can be the target of some query. This could include
	(eg.) multimedia or software; for simplicity, we'll refer to these all as
	"document".
identity
:	a user / node on the social network
in-arc, in-degree, in-node
:	Respectively: (an incoming arc, the total number of incoming arcs, a
	neighbour on the other side of an incoming arc) of the subject node.
local view
:	for a remote storage object $x$, the local view $\ddotx$ holds the parts of
	$x$ that have been retrieved from the network, ie. data that is immediately
	available to the local system. If $x$ is a container object, then $\ddotx$
	can distinguish between items found not to exist in $x$, and items not yet
	loaded.
neighbour
:	this refers to a node separated from the subject node by a single arc
node
:	in the context of a graph or a network, an object that can be connected to
	another node by an arc.
out-arc, out-degree, out-node
:	Respectively: (an outgoing arc, the total number of outgoing arcs, a
	neighbour on the other side of an outgoing arc) of the subject node.
semantics
:	this term is used in two different senses; hopefully the context should
	give enough disambiguation: the meaning of tags, wrt. the end-user; or the
	meaning of some concept, wrt. the theory of this system.
tag
:	a phrase that can be semantically related to a storage object

## Symbols

With no other context, the following symbols refer to the following object
types; capitalised symbols refer to the set of all objects of the given type.

- $d$ -- document
- $t$ -- tag
- $g$ -- `tgraph`
- $h$ -- `index`
- $p$ -- `ptable`
- $z$ -- identity
- $w$ -- weight, identity score

## Notation

- For any set $E = V_s \times V_t$ of arcs, define:
	- $\src E = \{ v_s \in V_s : \exists v_t . (v_s, v_t) \in E \}$ ie. the set
	  of nodes that the arcs point from.
	- $\dst E = \{ v_t \in V_t : \exists v_s . (v_s, v_t) \in E \}$ ie. the set
	  of nodes that the arcs point to.
	- $\rft E = \src E \cup \dst E$ ie. the set of nodes that E refers to.
- We deal with two types of data structures:
	- A map $V_A : V \to A$ of nodes to their attributes.
	- A map $E_A : E \to A$ of arcs to their attributes. For convenience, define:
		- $\src E_A = \src E$
		- $\dst E_A = \dst E$
		- $\rft E_A = \rft E$
- $f \subseteq X \to Y$ -- $f$ is a partial function from set $X$ to set $Y$.
	- This is non-standard but $f : X \to Y$ is confusing.

### Data structures

In the below notation, $\cdots$ denotes some additional predicate after a
subject, that serves as a specifier or definition for it.

Map $M = \{ x \cdots \mapsto y_x \cdots \} \quad | \quad M = \{ x_i \cdots \mapsto y_i \cdots \}_{i\cdots}$
:	A data structure that maps^[This is equivalent to a partial function: $M =
	\{ x_i \in X : y_i \in Y \}_i$ means the same thing as $M \subseteq X \to
	Y$; however (in my opinion) the former is easier for an implementor to
	read.] $x$ to $y_x$, or $x_i$ to $y_i$. In the second style, $i$ is a dummy
	variable used only to specify $x$, $y$ from the same pair; the actual value
	is unimportant and both $x_i$, $y_i$ are independent from it.
List $L = [ x_i \cdots ]_{i\cdots}$
:	A data structure that imposes an ordering $i$ on a collection of items
	$x_i$.

All data structures discussed from here onwards are implicitly finite in size.

## TODO and related tags

- `DIAG`: draw appropriate diagram here
- `TODO`: open issue; resolve or explain why we leave it open
- `MORE`: expand
- `EXTN`: a pointer to an external research topic, either potential or existing
- `REF`: add references for


# Overview

Distributed network of data structures maintained by multiple independent
parties.

Most of the routing power of the system is delegated to the underlying social
network and the innate information-retrieval heuristics we have as humans,
rather than being inherently built into the system.

How the properties of the system (performance, scalability, robustness) change
with the structure of the network forms the basis of the [analysis](#analysis).

The system has three main networks / planes of information that link to each
other.

- routing plane - see the `index` section
- naming plane - see the `tgraph` section
- contact plane - see the `ptable` section


# Specification

## Data structures

### Weight attributes

Structure
:	$w \in W = [0,1]$
Description
:	Aids comparison and composition of multiple nodes or arcs.

The precise meaning of a weight attribute is intrinsically linked with what the
routing and the ranking algorithms do. Specific uses include:

- priority of traversal of the routing and naming networks
- ranking of query results

Probability-based semantics seem quite robust and reliable, since these are
objective properties and can (in theory) be estimated algorithmically. It also
gives rise to a simple way of combining weights (multiplication), as well as a
simple interval of values $[0, 1]$.^[Depending on the precise meaning of the
weight, this could allow arcs with near-zero weights to be defined between
nearly all pairs of nodes. However, there would be no point to this, since it
would provide very little information (entropy). For a more in-depth discussion
of this, see [zero-weight attributes](#zero-weight-attributes).]

These weights allow algorithms to achieve a finer level of preference-choosing
than would otherwise be possible. However, care must be taken not to depend on
the precise values too much, or to treat the data as authoritative: even if
malicious data can be excluded, and the weights are defined on some objective
property, there will still be some degree of inconsistency between different
objects, since each publisher can only calculate weights from their subjective
(and limited) view of the entire network.

The best practical solution would be to have an automatic way of calculating
weight attributes. This would reduce the problem of human inaccuracy, as well
as laziness: it's tedious to manually estimate a weight for every object we
add to our collections. [EXTN]

### `index`

DIAG

Structure
:	$$
	h = \left[ \begin{array}{lrr} \\
	  E_h \subseteq & T \times D \cup H & \to W \\
	\end{array} \right]
	$$
Description
:	A map of arcs to their weights, where each arc is a relation from a tag to
	a document or another `index`.
Semantics
:	Probability that the arc target will satisfy a query for the source tag.

This data structure contains information on how to satisfy a search request. It
contains mappings from tags to target documents, or to another index to forward
the request onto.

A mapping indicates some semantic relevance between the tag and the document,
and a subjective judgement that a person searching for the tag did intend to
retrieve information provided by the document.

The analogy to typical navigable networks is that each tag is like an address;
and each `index` is like a routing table, mapping addresses to target entities.
^[Most "addresses" in this network will have multiple targets, but this is an
unimportant detail; eg. the internet has multicast addresses too.] So, we'll
call the network of `index` objects the "routing" plane.

Navigable networks have a well-defined addressing scheme, which enables routing
through a series of addresses to reach the target. For example, numerical
addresses (eg. IP) are naturally hierarchical, and can be prefix-matched upon
in a routing table. Tags however, do not intrinsically encode such information,
so we need an additional layer to provide it.

### `tgraph`

DIAG

Structure
:	$$
	g = \left[ \begin{array}{lrr} \\
	  V_g \subseteq & T \cup G & \to W \\
	  E_g \subseteq & T \times T \cup G & \to W \\
	\end{array} \right]
	$$
Description
:	1. A map of nodes to their weights, where each node is a tag; and
	2. A map of arcs to their weights, where each arc is a relation from a tag
	to another tag or `tgraph`.
Semantics
:	1. Saturation of the tag. (see [`tgraph` semantics](#tgraph-semantics))
	2. Relevance of the target tag to the source tag.

This data structure provides information on tags and the relationships between
tags. The presence of a tag indicates an understanding of its meaning; an arc
from a tag to a tag or `tgraph` indicates a semantic relationship between them,
and a judgement that the target can be used in some appropriate way to satisfy
a query for the source tag.

From a given root tag, we can reach other tags and `tgraph`s by following the
arcs between them. Weights on the arcs and nodes help us to adapt the traversal
order to our purposes.

The analogy to typical navigable networks is that the graph of tags provides
the same service as an addressing scheme or a name resolution system: a method
for navigating between related addresses. This works beyond the routing level,
so we'll call the network of `tgraph` objects the "naming" plane.

Conceptually, a tag can be thought of as a "pure" name - ie. the name carries
no information about its referent, such as its location). IP addresses are the
opposite, and DNS names are somewhere in between the two. DNS names need to be
resolved; likewise, we have an additional system here for tags.

### `ptable`

DIAG

Structure
:	$$
	p = \left[ \begin{array}{lrr} \\
	  V_p \subseteq & G \cup H & \to W \\
	\end{array} \right]
	$$
Description
:	A map of nodes to their weights, where each node is a `tgraph` or an
	`index`. Implicitly, each `ptable` "belongs" to some identity on the
	[underlying social network](#underlying-social-network).
Semantics
:	Probability that a ... TODO

This data structure allows an identity to declare a personal list of preferred
indexes and tgraphs to use for routing purposes.

This is intended to provide an attack-resistant "bootstrapping" path onto the
routing and naming planes.

MORE

## Algorithms

Since network latency is far greater than processing latency, we design these
algorithms to be inherently concurrent. Operations involving retrieval of
remote objects are non-blocking and allow other work to be done whilst waiting
for its results.

The system is partitioned into several layers, each dependent on the one below
it. The lower layers (contact, naming, routing) correspond to the data
planes introduced previously; the top layer provides the results to the user's
original query, and interacts directly with the user.

Each layer has an interface for interacting with the layer above it, and a
framework that co-ordinates between the various tasks that make up the layer.
Some are quite general and complex, and have a wide range of applications - so
these are specified as upgradable modules. For our prototype, we only suggest
some basic heuristics for these, and briefly comment on their reliability and
usefulness; better solutions can be explored by future projects.[EXTN]

The lower layers retrieve and process data from the appropriate plane. The
underlying algorithms have no "natural" termination condition; data retrieval
can theoretically proceed until the entire network has been searched. In
practice, each layer does not do this spontaneously; instead, they respond to
requests for data from the layer above. By default, we discontinue sending new
requests in all layers after a given number of results have been returned, and
allow the user to resume from the paused state, resources permitting.

DIAG information flow diagram

TODO rewrite this key for the new diagram

(Dot-arrow)
:	Synchronous flow of information. When data is updated in the source node,
	the target node is updated automatically.
(Cirle-arrow)
:	Event-triggered flow of information. When data is updated in the source
	node, the target node is updated only when explicitly requested, or when
	certain conditions are met.
(Square-arrow)
:	Asynchronous flow of information. When data is updated in the source node,
	the target node is updated automatically, but the operation completes only
	when all required data from the network has been downloaded.

The integrity of the system can be observed in the diagram: information only
move from lower layers to higher ones; within each layer, there are no cycles
that consist solely of synchronous data flows (ie. no infinite loops).

---------------------------------------------------
                requires    stores      provides
--------------- ----------- ----------- -----------
routing         $H_s$,      $\breveQ$,  $\breveh$
                $\breveT$   $\breveR$,
                $\breveg$   $\breveH$,
                            $\breveH_*$

naming          $t_0$,      $\breveG$,  $\breveT$,
                $G_s$       $\breveG_*$ $\breveg$

contact         $z$         $P_s$       $G_s$,
                                        $H_s$
---------------------------------------------------

Table: Data dependency between layers

TODO maybe talk about sending/receiving requests, making this parallel, etc

### Contact

Requires
:	- $z$ from the user
Provides
:	- $G_s$ to [naming](#naming)
	- $H_s$ to [routing](#routing)

MORE blah blah, why etc

Note that this layer is independent of any query, so this can be done in the
background at any time. We can cache data for the layers above, which will
help to increase performance for future queries. etc...

MORE on incremental updates etc.

#### Obtaining initial ptables

Assume a given identity is already connected to the social network. MORE

For our purposes, we need an algorithm which takes our own identity as input,
and outputs a set of seed identities for our routing algorithm, with a score
associated with each identity.

Given
:	- our own identity
Return
:	- a set of seed identities, with corresponding scores

A basic implementation of this would be to return all nodes up to 2 hops away
from our own node. This would grab a decent number of nodes whilst offering
a basic level of protection against the most common and simple attacks. A
variation would be to filter out the 2-hop nodes that share very few mutual
1-hop friends with us (by some standard); this would be slightly harder to
attack.

Inferring attacks from the link structure of a social network is outside the
scope of this project. More advanced algorithms exist; a real implementation of
this system would be able to use the latest available techniques. [REF][EXTN]

#### Combining `ptable` objects

Given
:	- a map $P_s = \{p \mapsto u_p\}$ of `ptable`s to their identity scores
Return
:	- a `ptable` $p_s$ that "combines" this information, with $\dom p_s =
	  \bigcup \dom p$.

Define $G_s = \dom p_s \cap G$ and $H_s = \dom p_s \cap H$. (Note that $G_s +
H_s = \dom p_s$).

A basic implementation is just to calculate the score-weighted average of the
weight of each node. Then, to generate $p_s[v]$ for any $v \in \bigcup \dom p$,
we just pass $P_s$, $v$ and some appropriate $\alpha_1 : P \times V \to [0, 1]$
through the [general algorithm](#mean-weight-of-a-node).

To recap, $\alpha_1(p, v)$ is the probability of $v \notin \dom p$ being due to
"zero-weight". In other words, $p$ does know about $v$ and has judged it to be
worthless. We need to make a rough estimate for $\alpha_1$.

Various factors that could affect $\alpha_1$ include:

A.  Maintainers of larger `ptable`s are likely to have come across more objects
    than those of smaller `ptable`s, and so $\alpha_1$ will be larger.
B.  The more of our friends that know about a particular item, the more likely
    it is that we also know about it. The probability is proportionally greater
    at lower saturations, since it only takes one friend to pass on knowledge.
C.  On the other hand, we might choose _not_ point to an item that our friends
    already point to, even if we like it. To do so would be somewhat redundant;
    we could just get the information from our friends instead.

It is not immediately obvious how these factors interact with each other, and
how they affect the final $\alpha_1$. Even if we can produce a global estimate,
it is uncertain whether it would actually be accurate or useful when applied to
an individual's local situation. [EXTN]

Also, any estimate depending on social factors (eg. (B), (C)) would require
retrieving the `ptable`s of all the friends of $p$, which is more costly than
estimates based on an individual `ptable`.

Selecting trustworthy nodes from a social network is a deeper and more general
problem which would provide resistance to attacks in this layer. With a good
algorithm, $\alpha_1$ could then be reduced to near-zero.

Due to these reasons, for our prototype we simply use a low constant, $2^{-4}$.
This is **not** theoretically sound, but should work adequately in the majority
of cases, where there are few disagreements or malicious attacks.

### Naming

DIAG

Requires
:	- $t_0$ from the user
	- $G_s$ from [contact](#contact)
Provides
:	- $\breveT$ to [routing](#routing)
	- $\breveg$ to [routing](#routing)

The purpose of the naming layer is to provide a routing scheme to the routing
layer. This scheme is dynamic, and updates are requesting by the routing layer
when it needs more information. The query state consists of these objects:

$\breveG_* = \{ g \mapsto \ddotg \}$
:	- a map of **data sources**, to the local view of each source.
	- Initialised with the keys of $G_s$, each mapped to an empty local view.
	- For any $g$, let $t$ is _complete_ in $\ddotg$ mean that enough data has
	  been retrieved to calculate any [distance](#distance-between-tags) metric
	  between $t$ and any of its out-nodes - ie. the weights of (itself, its
	  out-arcs, and its out-nodes). `tgraph` nodes have no out-arcs, so this
	  will just be its own weight.
	- Let $t$ is _complete_ in $\breveG_*$ mean that $t$ is complete in all
	  $\ddotg \in \img \breveG_*$.
	- Let $\com \breveG_*$ refer to the largest set of nodes for which every
	  node is complete in $\breveG_*$. This contains enough information to
	  generate the theoretically largest $\breveT$ for the given $\breveG_*$,
	  without waiting for more data from the network, or designing some extra
	  workaround for the missing data.
$\breveG = \{ g \mapsto w_g \}$
:	- a map of **data sources** to their [scores](#weight-of-new-tgraph).
	- Initially empty.
$\breveg \in G$
:	- a **combined `tgraph`**, [constructed](#combining-tgraph-objects) from
	  $\breveG_*$.
	- Initialised with $t_0$ having weight 1. This is just a temporary dummy
	  value to allow the routing layer to do an initial scan using just the
	  root tag, when naming information is still unavailable.
	- This holds all information related to $\com \breveG_*$; except for arcs
	  to `tgraph`s already being used as a data source (ie. all $g \in \dom
	  \breveG$).
$\breveT \subseteq \breveg$
:	- an **acyclic subgraph** of $\breveg$, representing a **routing scheme**.
	- Initially empty.
	- Nodes are ranked in order of its shortest distance to $t_0$, and each
	  node only has in-arcs from nodes nearer to $t_0$ than itself.
	  (TODO could rank these arcs too..)
	- This provides a quick way to obtain the set of short (ie. greedy) paths
	  from $t$ back to $t_0$. MORE explain better

Implementations may merge $(\breveG_*, \breveG)$ and $(\breveg, \breveT)$ into
the same objects; however, they should ensure that only the parts specified
here are exported to other layers.

DIAG data flow diagram

Receiving data from lower layers

:	We start from our seed `tgraph` set $G_s$. If $t_0$ does not appear in $G_s$,
	we have a few backup options:

	- ask the user to supply some related tags. This should not be a significant
	  problem; people usually "have an idea" of what they are looking for.
	- ask more nodes in the social graph for their `ptable`s. This could be done
	  automatically, which makes things more convenient for a user. However, it
	  increases the risk of an attack through the social network.

	TODO rewrite this so it's more relevant to the new layer-based architecture.

Evt+Async: $\breveG_* \to \breveG$

:	The events that can trigger this are:

	0. After receiving $G_s$ from [contact](#contact), in which case $G_s$ is
	   just copied to $\breveG$.
	1. A request from [routing](#routing) to add a tag to $\breveT$, in which
	   case we complete the last element of $\breveT$ in $\breveG_*$, and
	   continue our calculation of $\breveT$ (see below).
	2. A request from [routing](#routing) to add `tgraph` $g \in \breveT$ as
	   a data source, in which case we add $g$ to $\dom \breveG_*$, and
	   retrieve enough data to maintain $\com \breveG_*$.

	In each case, additional data may be need to be retrieved from the network.
	When this is complete, the updates can be pushed atomically (from the other
	layers' perspective) to $\breveG$, $\breveg$, $\breveT$.

	**(3 only)** This may require first completing $g$ in $\breveG_*$, if the
	weighting algorithm needs such data. Since this is costly and our prototype
	does not need it, we omit this step.

	**(3 only)** This may cause some $t \in \com \breveG_*$ to no longer be
	part of the shortest-path tree, and hence $\breveT$, which will cause
	future additions to retrieve unnecessary data from the network. In theory,
	we could check this and prune them; however this would be quite complex and
	should be rarely needed, so we ignore it in our prototype.

Sync: $\breveG \to^{\breveG_*} \breveg$

:	For each tag $t$ in $\com \breveG_*$, we calculate the combined weights for
	all of its out-arcs and out-nodes (from every data source), ignoring the
	`tgraph` nodes that have already been added to $\dom \breveG$ (so that they
	are not added to $\breveT$ and be made available for addition again).

Sync: $\breveg \to \breveT$

:	Our prototype uses Dijkstra's algorithm. Each step $n$ adds a node to
	$\breveT$; for this, we need to know the distances to all the out-nodes of
	the shortest-path tree so far, ie. $t_i$ must be complete in $\breveg$ for
	all $i < n$. TODO could split this into another module, allowing other
	methods of ranking to be used.

	1. If we reach a $t$ for which we don't have the data to continue, we pause
	   the algorithm, and give the routing layer the option to request that we
	   add another tag to $\breveT$ (by completing $t$ and continuing).
	2. For each `tgraph` node $g$ in $\breveT$, we give the routing layer the
	   option to request $g$ be added as a data source.

	(The numberings correspond to the "event trigger" specs above.)

#### Combining `tgraph` objects

Given
:	- $\breveG$
	- a node $v$, or an arc $e$
Return
:	- the combined weight $w_v$ or $w_e$, to be used in $\breveg$.

A basic implementation is just to calculate the score-weighted average value of
$v$ or $t$.

TODO semantics of tag-tgraph arcs

There are two cases to consider:

Weight of a node $v$
:	With `tgraph`s, the absolute weight of a single node does not determine
	its usefulness to the naming layer, but the "distance" between that node
	and the given query tag $t_0$. To this end, `tgraph`s are *supposed* to
	include any tag it knows about, including low-weight ones. Therefore, we
	assume that the absence of a tag *always* means "missing information", and
	let $\alpha_1(g, v) = 0$.

	We need to justify that the distribution of weight estimates is roughly
	even. TODO (see incorporate notes from below)

Weight of an arc $e$
:	We use the standard [mean weight](#mean-weight-of-an-arc) algorithm. This
	requires us to provide an $\alpha_1, \alpha_2$; these take low, high values
	respectively - see the [analysis](#zero-weight-attributes) for details.

	We need to justify that the distribution of weight estimates is roughly
	even. TODO

For node-weights, the "important" thing is not the value itself, but rather
where the most significant bit occurs. In other words, the outcome-entropy of
(D tagged by v), equal to -log(P(D tagged by v)).

When we combine saturations from various sources, then I think it's more
"correct" to take the mean of the entropy, and not the saturation. I'm not sure
how to justify this rigorously, but intuitively:

- if we have 3 sources giving saturations of (1, epsilon, epsilon), the mean
saturation is 1/3, whereas the actual value is likely to be nearer epsilon.

Is there a more formal way of saying this?

Also, "mean entropy" is theoretically open to manipulation, since entropy can
go all the way to infinity. But I don't think this is too much of a problem,
because:

- there is no incentive to manipulate these node-weights, since a tag must be
well-related to other tags for the search algorithm to be affected; and
arc-weights are not susceptible to this kind of manipulation
- CPUs practically have finite-size representations of numbers, which limits
the entropy to be proportional to the width (in bits) of the representation.
Also, we could do this manually.

#### Distance between tags

Given
:	- an arc $e = (v_s, v_t)$, and its weight $w_e$
	- a node $v_s$, and its weight $u_s$
	- a node $v_t$, and its weight $u_t$
Return
:	- a "distance" metric $d(v_s, v_t)$.

The distance metric should give some indication of how much $v_s$, $v_t$ are
related to each other, with lower values representing a closer relationship.
Furthermore, this should be additive, meaning that given $e_1 = (v_0, v_1)$,
$e_2 = (v_1, v_2)$, and no further information (ie. assuming that $(e_2, v_0)$,
$(e_1, v_2)$ are pairwise independent), then $d(v_0, v_2) = d(e_0) + d(e_1)$.

see [`tgraph` semantics](#tgraph-semantics) - want to maximise $u_t.w_e$, etc

so for any $e = (t_0, t)$, let $d(e) = -\log(w_e.u_t)$. MORE pad this out

#### Weight of new `tgraph`

TODO resync spec with new routing layer architecture

Given
:	- $\breveG_*$
	- $g \in \dom \breveG_* \notin \dom \breveG$
Return
:	- a weight $w_g$ to assign to $g$ in $\breveG$

TODO

see [object-object links](#object-object-links)

### Routing

DIAG

Requires
:	- $H_s$ from [contact](#contact)
	- $\breveT$ from [naming](#naming)
	- $\breveg$ from [naming](#naming)
Provides
:	- $\breveh$ to the user

The purpose of the routing layer is to retrieve results and provide these to
the user. The results set is dynamic, and updates are requested by the user
when it needs more information. The query state consists of these objects:

$\breveH_* = \{ h \mapsto \ddoth_H \}$
:	- a map of **data sources** to a partial local view of each source.
	- Initialised with the keys of $H_s$, each mapped to an empty local view.
	- This only holds arcs to other `index`s; arcs to documents are stored in
	  $\breveR$ (see below).^[Contrast this with $\breveG_*$ from naming, which
	  holds all retrieved data, due to the different structure of a `tgraph`.]
	- TODO explore and explain the reasons why we have a $\com \breveG_*$ but
	  not a $\com \breveH_*$.
$\breveH = \{ h \mapsto w_h \}$
:	- a map of **data sources** to their [scores](#weight-of-new-index).
	- Initially empty.
$\breveQ = \{ h \mapsto T_h \}$
:	- a map of **data sources** to sets of tags, representing the currently
	  **active lookup** operations.
	- Initially empty.
	- Here, we distinguish between the _query_ for tag $t_0$, which is the
	  objective of this entire process , and the simpler operation _lookup_,
	  which simply returns the results for a tag in a single `index`.
$\breveR = \{ h \mapsto \ddoth_D \}$
:	- a map of **data sources** to a partial local view of each source,
	  representing the **results** of lookup operations.
	- Initially empty.
	- This holds the entire local view, except for arcs to `index`s already
	  used as a data source (ie. all $h \in \dom \breveH$).
	- Let $\breveD = \dst \bigcup \ddoth_D$ be the set of all results (from
	  every data source).

Implementations may choose to merge any of these objects together; however,
they should ensure that only the parts specified here are exported to other
layers.

DIAG data flow diagram

Evt: $\breveH_* \to \breveH$

:	The events that can trigger this are:

	0. After receiving $H_s$ from [contact](#contact), in which case $H_s$ is
	   just copied to $\breveH$.
	1. After adding $h \to \dom \breveH_*$ (see below), and its lookups have
	   all completed, in which case we update $\breveH$ by calling the scoring
	   algorithm.

	TODO explain this much much better... maybe waiting is not necessary and we
	can just update $\breveH$ every time we receive data from $\breveR$...

Evt: $\breveH_* \to^\breveT \breveQ$

:	The events that can trigger this are:

	1. A request from the user to add a `index` $h \in \breveD$ as a data
	   source, in which case we add $h$ to $\dom \breveH_*$, and update
	   $\breveQ$, etc... TODO explain this much better....
	2. Receive an update to $\breveT$ from [naming](#naming), in
	   which case we update $\breveQ$ etc.

	For each `index` $h \in \breveH$, we want to select the tags to lookup.

	- if $h$ is from $H_s$, select all tags in $\breveT$.
	- otherwise, use $\breveH_*$ to find all tags $t$ than we reached $h$ by,
	  and then use $\breveT$ to select all "short" paths from $t$ to $t_0$.
	  TODO clarify this, description already in naming

	Do this when $\breveT$ is updated from [naming](#naming).

Async: $\breveQ \to^\breveP \breveR$

:	We run the lookups of $\breveQ$ in some [order](#deciding-lookup-order),
	and update $\breveR$ with the results. We can execute these in parallel.

Sync: $\breveR \to \breveH_*$

:	When a lookup $(h, t)$ completes, we scan the results returned, and add
	any arcs to `index`s to the relevant $\ddoth \in \breveH_*$. We also remove
	arcs to any `index` nodes that have already been added to $\dom \breveH$
	(so that they are no longer available for addition again).

	TODO explain this better

#### Deciding lookup order

Given
:	- $\breveQ$
	- $\breveT$
	- $\breveH_*$
Return
:	- an ordered list $\breveP = [(h_i, t_i)]$, where $(h, t) \in \breveP \iff
	  h \in \dom \breveQ \wedge t \in \breveQ[h]$.

Tags further away from the root are less "related" to the original query, but
searches for them are more likely to succeed (for rare searches), so the
algorithm should proceed by searching near the root, then further up the tree.

However, note also that tags with higher $u_t$ are more likely to have their
search queries succeed, independent of $w_e.u_t$.

TODO rewrite this...

#### Weight of new `index`

Given
:	- $\breveH_*$
	- $h \in \dom \breveH_* \notin \dom \breveH$
Return
:	- a weight $w_h$ to assign to $h$ in $\breveH$

TODO

see [object-object links](#object-object-links)

#### Combining results from different queries

Given
:	- $\breveg = \{ t \mapsto w \}$
	- $\breveH = \{ h \mapsto w \}$
	- $\breveR = \{ h \mapsto \{ t \mapsto \{ d \mapsto w \} \} \}$
Return
:	- $\breveh = \{(d, w_d)\}$, a results map of documents to their weights.

TODO

possibly could just merge this into routing.

## Optimisation

### Data structures

- `ptable`
	- quick partition of `index` vs `tgraph` nodes [$G_s$, $H_s$]
	- optionally order these by their score [possible future use]

- `tgraph`, `index`
	- where applicable:
	- quick lookup of node (and weight)
	- quick lookup of node's out-arcs (and weight) [routing, naming]

- `index`
	- quick partition of tag's to-`index` vs to-document arcs
	- optionally order these by their score [routing]

- $\breveg$
	- same as `tgraph`

- $p_s$, $\breveg$, $\breveG$, $\breveH$
	- might want to make these use CombinedWeight objects instead of a float
	  "weight", which in the future could be expanded to include a variance...

- $\breveT$
	- quick lookup of node (and weight)
	- quick iteration through all nodes [$\breveQ$]
	- quick comparison of nodes by their distance ordering [$\breveP$]
	- quick lookup of node's in-arcs (and weight) [$\breveQ$]

- $\ddotg \in \img \breveG_*$, $\ddoth \in \img \breveH_*$
	- quick lookup of node (and weight)
	- quick iteration through all nodes, arcs [$\breveg$]
	- quick lookup of node`s in-arcs (and weight) [routing, naming]
	- quick lookup of node's out-arcs (and weight) [maybe needed by some
	  scoring modules]
	- quick one-time check that all of a node's out-arcs (and weight) have
	  been retrieved from the network [routing, naming]

- $\breveQ$, $\breveR$
	- quick iteration of all lookups/results [$\breveP$, $\breveh$]
	- an advanced implementation would allow items to be added and dynamically
	  ordered in priority, bypassing the need to have $\breveP$, $\breveh$.


### Retrieval of remote objects

Usually we only need to retrieval part of a `tgraph` or `index`, eg. the weight
of a single node, or its out-arcs.

- eg. for quick "no" answer on lookups of storage objects - bloom filters

### Caching storage objects

- eg. cache commonly-retrieved objects like `ptable`s

### Incremental state updates

- eg. when updating $\breveG$ from $\breveG_*$, we should only need to
  recalculate the parts that are affected by the updated....


## UI

### Components

### Behaviour



# Design

## Objectives

## Assumptions

### Abstract storage network

Our search system assumes that its data objects are located on some abstract
lower-level storage network. Data objects can always be retrieved, instead of
being stored locally with its maintainer, who may be offline. This simplifies
our design, since it allows us to avoid dealing with the issue of churn by
delegating it to an independent component. [EXTN]

This also forces us to consider a iterative routing algorithm rather than a
recursive one, since data objects are "dumb" and cannot respond to dynamic
queries. Instead, a requestor must retrieve the data, process it themselves,
then pull in further data, etc.

Any distributed storage network that has a global address scheme (such as a
binary-key address space) would be suitable, since pointers to objects can be
represented simply as its address. This includes all Distributed Hash Tables
(DHTs), as well as more complex cryptokey-based addresses such as Freenet's
Signed Subspace Keys network.

### Underlying social network

The initialisation algorithm assumes an abstract lower-level social network
where it can look for friends to query for pointers onto the naming and routing
planes.

Any system which has a social network as a major component, needs a method
of constructing such a network and sustaining its growth. Fortunately, such
systems are already widely deployed on the www; new networks can bootstrap
themselves by extracting social data from existing networks, through invites,
etc. [EXTN]

The network is modelled as a directed weighted graph; arcs represent a degree
of trust by the source node in the target node, and arc weights are restricted
to the interval $[0,1]$.

This model is sufficiently general for our purposes. Many social networking
websites only recognise mutual friendship; this is a degenerate form of the
model, where all weights are constant and all arcs have a reverse-direction
counterpart.

The naming and routing planes also form what is essentially a social network -
`tgraph`s and `index`es effectively contain pointers to each other, through
their arc targets. However, these also carry semantic information (each arc has
a source tag) and are intrinsic to our search system; by constrast, the social
network used for initialisation carries no semantic information and is
independent of our system. To highlight this difference, we refer to a node on
the social network as an "identity", and arc weights as "identity scores".

MORE talk about churn, virtual social networks (WoT on Freenet's SSK), etc

MORE proxy services

## `tgraph` semantics

The routing algorithm needs some way of inferring which tags (out of a related
set) are more "general" or "specific".

Our first thought was to have arcs represent a relationship from a more
"specific" tag to a more "general" tag. However, this is problematic since:

- The relationship is supposed to be transitive, but our graph can potentially
  contain cycles, especially when pulling in data from several sources. We
  don't want to be tied up devising a complex algorithm to resolve this.
- We potentially would like to traverse from general to specific tags, as well
  as vice versa; and arc targets are the only mechanism of doing this between
  `tgraph`s.^[Within a `tgraph`, arc sources ("reverse" pointers) could in
  theory be calculated quickly, depending on the implementation.]

MORE

The following model addresses these shortcomings.

For a given tag $t$, let $D(t) = \{ d \in D : d \textrm{ tagged with } t \}$.
Define the "saturation" of $t$ to be $\frac{|D(t)|}{|D|}$, and the "relevance"
of $t$ to $t_0$ to be $\frac{|D(t) \cap D(t_0)|}{|D(t)|}$. An equivalent model
is to treat $D$ as a random variable, evenly distributed over all documents in
the network. For a given tag $t$, the saturation of $t$ is equivalent to $P(D
\textrm{ tagged with } t)$, which we shorten to $P(t)$ for convenience.
Likewise, the relevance of $t$ to $t_0$ is equivalent to $P(t_0|t)$.

We then use these to define:

- the weight $u_t$ of a node $t$ to be $P(t)$, its saturation.
- the weight $w_e$ of an arc $e = (t_0, t)$ to be $P(t_0|t)$, the relevance of
  the target tag to the source tag.

These values are straightforward to calculate, so this process can (in theory)
be automated. Note also that given $u_{t_0}$, $u_t$ and $w_e$, the weight of
$e^- = (t, t_0)$ can be derived using Bayes' theorem, as $w_e.u_t/u_{t_0}$. If
the `tgraph` implementation allows quick lookups of an arc both by its source
node and its target node, then it might be sensible to not explicitly define
the weight of the reverse arc.

We can think of `tgraph` $g$ (containing tags $t_i$), as a single tag over all
documents tagged by any $t_i$, and define saturation and relevance accordingly.
That is, $P(g) = P(\bigcup t_i)$ and $P(t_0|g) = P(t_0|\bigcup t_i)$. Note that
these values give no information on how well-connected a `tgraph` is within the
naming network. However, a `tgraph` consists of highly compressed data on a
large section of the storage network, so in practice the vast majority of our
naming needs should be satisfied by a small neighbourhood around our seed set.
Choosing between `tgraph`s probably won't be very important, so for now we
ignore this deficiency.[EXTN]

Now for the analogy to typical navigable networks: a tag $t$ can be thought of
as defining a subnetwork - the set of documents tagged with $t$. $P(t)$ tells
us the size of this subnetwork, and $P(t_0|t)$ tells us the proximity between
two subnetworks.

For example, $P(t)$ roughly corresponds to the CIDR routing prefix used by the
current internet. In ring-topology networks, such as some DHTs, neighbours are
matched by the numerical value of the network address; by contrast, internet
routers update each other with their nearest neighbours; and here, we provide
this information in the form of $P(t_0|t)$.

In routing terms, if our end target is $t_0$, then we want to pick a $t$ such
that $P(t_0 \cap t)$ is maximised - for the above model, this is $u_t.w_e$.

This raises the question of why we don't just define $w_e$ as $P(t_0 \cap t)$,
which would also remove the need to define $u_t$. However, this would destroy
our ability to quickly look up $P(t)$ and $P(t_0|t)$. On a distributed network,
we need to be able to combine data from multiple sources; algorithms to do this
may well need knowledge of the separate values.

## Links between objects

### Identity-object links

vs. all-data-in-identity and identity-identity pointers

### Object-object links

vs. identity-object links

Scalability - decreases the number of identity-object pointers

- requires less effort than forming a social link
- has less implications than a social link - only endorse information contained
  there, and possibly a small number of steps away

MORE

whether to use social link structure - flawed because:

- MORE using two different semantic meanings for weight attributes being used
  here (relevancy vs reliability) TODO explore this and its potential pitfalls.
- would need to expand `tgraph` to provide this information more efficiently
  (ie. have a "referents" table)

TODO talk about endorser of a node vs maintainer of a node - two different
things (here "node" refers to `tgraph` or `index`)

- **maintainer** of a node defines its nodes and its out-arcs, and provides no
  information about any other nodes beyond its out-neighbours
- **endorser** of a node points to it in its `ptable`, and may follow out-arcs
  to potentially reach _any_ other nodes in its connected component of the data
  network

In other words, when scoring nodes not in our seed set, we must **not** use
weight information from nodes themselves (including the seed nodes), since this
information comes from the _maintainer_ and not the _endorser_. It might be
feasible to extend `ptable` to allow endorsers to provide extra information to
help the scoring process [EXTN].

Below, we explore a rough and basic heuristic to infer scores using only the
link structure of the data network.

MORE

Let $x$ be the node (here, a `tgraph` or `index`) we want to infer a score for.
For each seed node $s$, let $w_{p(s)}$ be the probability that $x$ will satisfy
a query, by traversing some path from $s$ to $x$. (If there is no path, the
probability is obviously 0). The weight of $x$ we might then calculate as:

$$
1 - \prod_s (1 - w_{p(s)})
$$

This is just the union (over $s$) of all path weights, assuming that paths are
independent. A rough justification for this is that we only need to traverse
one path to satisfy a query; we can pick any one we wish.

This is open to attack by multiple colluding seed nodes (which breaks the
assumption of independence), but in such cases, worse attacks are possible.
TODO explore more...

This leaves us to derive a model for $w_{p(s)}$. A simple one is:

- $w_{p(s)} = w_s.k^i$, where $k$ is some constant, and $i$ is the number of
  steps in the shortest path from $s$ to $x$.

$k^i$ represents the probability that the people who endorse $x$, also endorse
an object $i$ steps away from it. Suppose that the endorser follows a node's
out-arcs with probability $k$ (ie. the endorsement also covers the out-node).
Traversing $i$ steps involves following each arc in the path, and therefore has
probability $k^i$.

This ignores several important factors. For example:

- for nodes with larger out-degree, a typical endorser will follow a smaller
  proportion of its out-arcs.
- an endorser is more likely to visit a node that can be reached in more ways
  from $s$ (ie. has more distinct paths to $s$). This is essentially the same
  point as our "union" method above for all $s$.
- an endorser is less likely to traverse another step, the more steps they
  already are from $s$.

Some of these suggest potential vectors of attack upon the $k^i$ scheme. For
example, the assumption that the proportion of out-arcs followed is constant,
could encourage a malicious seed node to define huge numbers of out-arcs, whose
referents will then enjoy a larger path weight than appropriate. (This attack
is easy to detect, but there may be more effective ones.)

This problem can be stated more generally as: _Given an endorsement of a node
in a (social) network, what other nodes can I infer that the endorsement also
covers, and to what degree?_ [EXTN]

For our prototype, we stick to $k^i$. Due to the security concerns, we try to
give an underestimate for $k$. This should not affect the reachability of the
nodes in the network; only that near nodes (to our seed set) will have a much
greater priority than far nodes. Attacks from far nodes can only affect other
far nodes; and we also have the option of constructing local overrides against
the attacks that are detected.

TODO make an actual estimate... $2^{-4}$. [EXTN]

### Mutable vs immutable objects

security / trust issues

## Weights

### Zero weight-attributes

The current data structures can only represent the presence of an attribute,
and not its absence. This is a problem: any distributed system has to be able
to deal with incomplete information, but here there is no way to tell if the
absence of an object from a collection is due to incomplete information, or an
explicit rejection based on the semantics of the object attributes. This is
important when (eg.) we combine weights from multiple sources - we need to know
whether others disagree with a recommendation, or merely don't know about it.

We can either require that explicit "zero" weight-attributes are defined for
every item encountered, no matter how insignificant; or we can try to generate
heuristics for resolving this ambiguity, based on other implicit information.

**For a node-map**, the former results in linear data growth in the number
of items (nodes) encountered. This is not too bad, but can become inefficient
if the vast majority of items encountered are assigned to zero weights, and the
algorithms that process the data are designed to ignore them. With regards to
our system, this probably affects `ptable`s more than `tgraph`s, where the
algorithmic usefulness of a tag is largely unrelated to its weight.

Within a single node-map, there is no information that could be used to perform
any heuristic: a node not included in the map has no information relating to it
in the map. However, it may be possible to extract information from other
sources, such as the friends for a `ptable`. These are context-specific and
are explored in the appropriate sections. [TODO add link]

**For an arc-map**, the former approach results in quadratic data growth in the
number of items (nodes) encountered, since we need to define _something_
(either a relationship or its absence) between all _pairs_ of nodes. This is
not scalable; fortunately an arc-map holds more information than a node-map,
which allows for better ambiguity-resolution heuristics.

Since the meaning of $e = (v_s, v_t)$ is fully determined by $\{v_s$, $v_t\}$,
the maintainer has enough information to decide whether to include $e$ in $E$
if it "knows about" both $v_s, v_t$. Roughly, we can represent this notion as
$v \in \rft E$. In other words, if $e \notin \dom E$ but $v_s, v_t \in \rft E$,
then either the maintainer has overlooked the relation between $(v_s, v_t)$, or
there is no such relation (ie. a "zero weight"). The latter is more likely,
since people generally review things before publishing, and the mistakes that
do slip through are fixed over time.

Specific examples of this general principle, as well as applications of it,
are explored further in relevant sections of the [Algorithms](#algorithms)
chapter.

### Negative weight-attributes

A related idea is negative weight-attributes, which would represent a judgement
that the subject is malicious (in some sense), rather than neutral or "useless".
In a network where it's possible to act aggressively towards particular nodes,
these weights could provide information on who to attack (or equivalently, set
up defences against), and in what way.

As it stands, our search system is a "dumb" network of data; the only way of
interacting with other nodes is by publishing data objects for other nodes to
read. We are unable to see other nodes' read requests, so it's impossible to
attack a particular node. In this case then, negative weights are not useful.

There are other complications with negative weights in general. These would be
relevant if our search system is adapted into a form where one *can* perform
targeted acts of aggression.

- If positive weights are taken to be probabilities, it's not obvious what
  negative weights should mean. If the semantics of the data structure are not
  well-defined, the algorithms that use it cannot be, either.
- Depending on the algorithm used to combine weights from multiple sources,
  negative weights may allow the weight system itself to be used as an attack
  vector. (Otherwise, this was already possible with positive-only weights and
  the introduction of negative weights makes no difference.)
- MORE

### Corruption of weights

Scoring systems are susceptible to manipulation... the usual path to corruption
is that original semantics of the system are no longer reflected in algorithms
for calculating and evaluating it. When this happens the system breaks...

(eg. google's "trusted ads" are 2x likely to be corrupt)

## Combining data from multiple sources

Below, we describe algorithms for combining data from multiple sources. Our
model is relatively simple: we have a list of sources with a weight judgement
on how "good" each source is; in turn, each source specifies their own weight
judgement for each object that it refers to. To avoid confusion, we will call
source-weights "scores" and object-weights "values". Given a target object, we
want to derive a "combined" value for that object, using the given information.

TODO discuss more complex schemes that return "variance" for values. This would
allow further refinement, eg. the more data sources that give a value judgement
for some object $x$, the smaller the variance would be. [EXTN].

For our prototype, we use a very basic algorithm - the score-weighted mean
value of the object. Generally, the arithmetic mean is susceptible to attacks
and distortions. Let $k$ be the proportion of the total score that the attacker
controls. Weights are [limited](#weight-attributes) to $[0, 1]$, so this will
roughly be the same as the proportion of compromised nodes.

If the value is evenly distributed, the effect of an attack will be limited in
direct proportion to $k$ - the worst thing they can do is give a single value
with $k$ influence in the final result. However, if the value is far from being
evenly distributed, it would be possible for an attacker to introduce a value
that has an extremely small probability $\epsilon$ of occuring, yet which will
still have a $k$ share of influence in the final combined value.

TODO - explain this better.

So the types of weights that are input to this algorithm must be roughly evenly
distributed in order to be secure. Most distributions probably will not cause
too many problems; however, negative-log distributions will.

The algorithms below make use of several $\alpha_i$ functions, which fine-tune
the output based knowledge of on the context of the inputs. There are various
ways of producing such functions; one method is to extract realistic values
for some constant, by collecting training data from a prototype network. More
advanced techniques include collecting data directly from the active network,
to adjust the values dynamically. [EXTN]

However, such methods are likely to be quite complex, and so this project does
not go into them. Instead, we only explore heuristics that give a rough
approximation, based on our intuitions. TODO rewrite...

### Mean weight of a node

Given
:	- a map $M = \{ m \mapsto u_m \in W \}$ of data sources to their scores,
	  where each data source $m = \{ v \in V \mapsto w_{mv} \in W \}$ is a map
	  from nodes to their values.
	- a given node $v \in \bigcup \dom m$
Return
:	- the map-weighted mean node-weight $\bar w_v$ of $v$

The mean weight for node $v$, over all maps, is $\frac{\sum_{m} w_{mv}}{|M|}$.
If we take into account the weights of each map, we have $\frac{\sum_{m} u_m
w_{mv}}{\sum_m u_m}$. However, not every map will necessarily contain $v$, so
some $w_{mv}$ may be undefined. In such cases, we estimate a weight instead;
see the section on [zero weights](#zero-weight-attributes) for more details.
Following on from that, we reach:

$$
\bar w_v = \frac{\sum_{m} u_m \hat w_{mv}}{\sum_m u_m}
\quad ; \quad
\hat w_{mv} = \left\{ \begin{array}{llr} \\
  w_{mv} & : v \in \dom m & (0) \\
  \alpha_1(m,v).0 + (1 - \alpha_1(m,v)).\bar w_v & : v \notin \dom m & (1) \\
\end{array} \right
$$

where $\alpha_i(m, v)$ is the probability that the author of $m$ has judged $v$
to be worthless, given $(i)$.

The above definition has $\bar w_v$ on the RHS; after rearranging, we get:

$$
% should be \dfrac but LaTeXMathML doesn't support amsmath commands...
\bar w_v = \frac{\sum_{m:(0)} u_m w_{mv}}{\sum_m u_m \alpha(m,v)}
\quad ; \quad
\alpha(m,v) = \left\{ \begin{array}{ll} \\
  1 & : (0) \\
  \alpha_1(m,v) & : (1) \\
\end{array} \right
$$

Generally, the behaviour of $\alpha_i$ are likely to depend highly on the use
context, so this should be an additional parameter to the algorithm.

### Mean weight of an arc

Given
:	- a map $M = \{ m \mapsto u_m \in W \}$ of data sources to their scores,
	  where each data source $m = \{ e \in E \mapsto w_{me} \in W \}$ is a map
	  from arcs to their values.
	- a given arc $e = (v_s, v_t) \in \bigcup \dom m$
Return
:	- the map-weighted mean arc-weight $\bar w_e$ of $e$

The formula is similar to the one from the previous section, but here we are
dealing with arcs, so we can refine our estimate somewhat further; see the
section on [zero weights](#zero-weight-attributes) for more details. Following
on from that, we reach:

$$
\bar w_e = \frac{\sum_{m} u_m \hat w_{me}}{\sum_m u_m}
\quad ; \quad
\hat w_{me} = \left\{ \begin{array}{llr} \\
  w_{me} & : e \in \dom m & (0) \\
  (1 - \alpha_1(m,e)).\bar w_e & : e \notin \dom m \;\wedge\; \{ v_s, v_t \}
    \not\subseteq \rft m & (1) \\
  (1 - \alpha_2(m,e)).\bar w_e & : e \notin \dom m \;\wedge\; \{ v_s, v_t \}
    \subseteq \rft m & (2) \\
\end{array} \right
$$

where $\alpha_i(m, e)$ is the probability that the author of $m$ has judged $e$
to be worthless, given $(i)$.

The above definition has $\bar w_e$ on the RHS; after rearranging, we get:

$$
% should be \dfrac but LaTeXMathML doesn't support amsmath commands...
\bar w_e = \frac{\sum_{m:(0)} u_m w_{me}}{\sum_m u_m \alpha(m,e)}
\quad ; \quad
\alpha(m,e) = \left\{ \begin{array}{ll} \\
  1 & : (0) \\
  \alpha_1(m,e) & : (1) \\
  \alpha_2(m,e) & : (2) \\
\end{array} \right
$$

Generally, the behaviour of $\alpha_i$ are likely to depend highly on the use
context, so this should be an additional parameter to the algorithm.


# Analysis

## Data extraction and processing

last.fm, flickr

social network - relatively easy

### Transforming a simple graph into a `tgraph`

tgraphs arcs have weight and direction

## Test networks

### Inter-node properties

- neighbour count (ie. degree) distribution
- neighbour semantic relation distribution

### Intra-node properties

- semantic unity (how "related" its tags are)
- semantic specialty (how "general" its tags are)

### Generation algorithms

- Use network formed by extracted data ("real world")
- Barabsi-Albert model (preferential attachment)
  - scale-free
  - not small-world; according to wikipedia:
    - clustering coefficient is power-law, similar to hierarchical networks
    - small-world networks have constant clustering coefficient
- TODO etc. read up on network theory.
- hierarchies
- other structures?

Ideally we want a single algorithm which takes as input, various parameters for
the properties listed in the previous two sections, and outputs a random graph
with those properties.

## Simulation

### Request models

### Network conditions

- perfect conditions
- random failure
- malicious attacks - under the assumptions of "abstract storage network", only
  attacks vs the entire network can occur on the naming / routing planes.
  attacks vs individuals on the social plane is a separate topic, ignore here
	- attacks vs most well-connected nodes
	- MORE

