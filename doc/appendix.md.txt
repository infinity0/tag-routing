% Appendices
% Ximin Luo

# Bibliography

etc etc etc
[MORE]


TrueSkill http://research.microsoft.com/en-us/projects/trueskill/details.aspx

Dangalchev, C. Residual closeness in networks, 2006.

[SURV]: John Risson, Tim Moors, Survey of research towards robust
peer-to-peer networks: Search methods, _Computer Networks_, **Volume 50**,
**Issue 17**, 5 December 2006, Pages 3485-3521, ISSN 1389-1286, DOI:
[10.1016/j.comnet.2006.02.001](http://www.sciencedirect.com/science/article/B6VRG-4JD0XYW-1/2/07e1ec0ba8cbe65f8f094cd99612b149).

[REF] REMINDIN'

[REF] Harnessing.


## Comparison

Our design differs considerably from these; for example, REMINDIN's design is
more ontology focused, whereas ours draws from existing non-semantic routing
principles, DHTs in particular. Our design also has a well-defined (albeit
underdeveloped) model of the address space (unlike Harnessing). [MORE]


# Appendices

## Glossary

arc
:	A directed relation $e = (v_s, v_t)$ from node $v_s$ to node $v_t$.
degree, in-degree, out-degree (of a node-set $V$)
:	See "neighbour (of a node-set $V$)". the \*-degree is just the number of
	\*-neighbours
document
:	A storage object that can be the target of some query. This could include
	(eg.) multimedia or software; for simplicity, we'll refer to these all as
	"document".
identity
:	A node ("user") on the social network
independent union (of a set of probabilities $P$)
:	The probability of at least one event in $P$, assuming all the events are
	independent, given by $1 - \prod_{p \in P} (1 - p)$.
local view
:	For a remote object $x$, the local view holds the parts of $x$ that have
	been retrieved from the network, ie. data that is immediately available to
	the local system. It can distinguish between items found not to exist in
	$x$, and items not yet loaded.
neighbour, in-node, out-node (of a node $v$)
:	A node separated from $v$ by a single arc. We abbreviate "in-neighbour",
	"out-neighbour" to just "in-node", "out-node". We denote the set of all
	neighbours, in-nodes, out-nodes, of $v$ as $\nbrv$, $\predv$, $\succv$.
neighbour, in-node, out-node (of a node-set $V$)
:	We define $\nbrV = (\bigcup_{v \in V} \nbrv) \setminus V$; and $\predV$,
	$\succV$ similarly.
node
:	In the context of a graph or a network, a unique individual
resource relationship, route
:	We write $p \rightarrow^t p'$ to mean that $p$ points to $p'$ via tag $t$.
	In the relevant contexts (e.g. if $p$, $p'$ are tgraphs / indexes), this
	also means that $p$ defines an arc $(t, p')$ as a resource.
tag
:	A semantic unit used to describe documents in a useful way to end users.

## Notation

Here, we document the notation we use for describing the data structures we
use. All are implicitly finite in size.

Partial function $f \subseteq X \to Y$
:	This is non-standard, but $f : X \to Y$ is ambiguous - existing literature
	uses it to mean both a partial or a total function, depending on author.

### Simple objects

Tuple $X = ( a,b,\ldots )$
:	an ordered container of items, of fixed size
:	- the parentheses may be omitted when the context is clear
Union $U = ( a|b|\ldots )$
:	a container holding a single value of any of the specified types
:	- the parentheses may be omitted when the context is clear
Map $M = \{ x : y \}$
:	a container that maps[^mapfn] $x$ to $y$.
:	- write $y_x$ to mean "the $y$ that	$x$ maps to".
	- let $x \in M$ mean the same thing as $x \in \dom M$.
	- the braces may be omitted when the context is clear
List $L = [ x_i ]_{i}$
:	an ordered container of items, of unfixed size

[^mapfn]: This is equivalent to a partial function: $M = \{ x_i \in X \mapsto
y_i \in Y \}_i$ means the same thing as $M \subseteq X \to Y$; however, the
former is a better description of a static data structure.

### Composite objects

We make heavy use of these container objects:

- maps $V_A : V \to A$ of nodes to their attributes.
- maps $E_A : E \to A$ of arcs to their attributes.

These are used in various combinations to represent graphs, inverted indexes,
etc.

For any set $E \subseteq V_s \times V_t$ of arcs, define:

- $\src E = \{ v_s \in V_s : \exists v_t . (v_s, v_t) \in E \}$ ie. the set
  of nodes that the arcs point from.
- $\dst E = \{ v_t \in V_t : \exists v_s . (v_s, v_t) \in E \}$ ie. the set
  of nodes that the arcs point to.
- $\rft E = \src E \cup \dst E$ ie. the set of nodes that E refers to.

For convenience, let this also apply to arc-attribute maps, ie. $\rft E_A =
\rft E$.

## Derivations

### Ranking results

Aggregating the information from various indexes gives us a map $E_{\barh}$ of
tag-document arcs to attributes. For all $(t, d) : w$, where $w = P(t|d)$, we
want to normalise this to $(t_0, d) : w'$, where $w' = P(t_0|d)$.

For any tag $t$, let $[t_i]_0^n$ be the shortest path from $t_0$ to $t$, where
$t = t_n$. From the address scheme, we have the distance between $t$ and $t_0$:

$$
D(t) = D[t_i]_0^n = \prod_{i=0}^{n-1} P(t_{i+1}|t_i)
$$

If we assume that the pairs $P(t_{i+1}|t_i)$, along with $P(t_n|d)$, are all
independent[^routin] of each other, then we have:

$$
\begin{array}{rl}
D(t)
=& \prod_{i=0}^{n-1} P(t_{i+1}|t_i) \\
=& \prod_{i=0}^{n-1} P(t_{i+1}|t_i, \ldots, t_0) \\
=& P(t_n, \ldots, t_1|t_0) \\
\end{array}
$$

so that:

$$
\begin{array}{rl}
D(t) \frac{P(t_0)}{P(t_n)} P(t_n|d)
=& P(t_n, \ldots, t_1|t_0) \frac{P(t_0)}{P(t_n)} P(t_n|d) \\
=& P(t_{n-1}, \ldots, t_0|t_n) P(t_n|d) \\
=& P(t_n, \ldots, t_0|d) \\
\end{array}
$$

Since $[t_i]$ is the shortest path, we assume that $P(t_n, \ldots, t_0|d)
\approx P(t_0|d)$. So, for each $(t, d) : w$, we have:

$$
w' = D(t) \frac{P(t_0)}{P(t)} w
$$

as an approximation.

[^routin]: This assumption is unlikely to be true, but it's a common assumption
in information retrieval, and appears to give reasonable results.

### Type-parameters

Our design uses several types of objects without making any comment on their
type; these include tags, object addresses (in the storage layer), and social
identities. These are perfect candidates for generic type parameters.

The type of attributes can also be parameterised. Although we use probability
for all of our attributes, this is a part of our specification that is separate
from the overall architecture of the system. A full list of theoretically
distinct types is:

   Source                              Description
-- ----------------------------------- -----------------------------------
1. agent score (social)                social identity trust score
2. resource value (social) (tgraphs)   rating score for tgraphs
3. resource value (social) (indexes)   rating score for indexes
4. agent score (naming)                rating score for tgraphs
5. resource value (naming) (node)      tag size
6. resource value (naming) (arc)       tag-tag similarity
7. agent score (routing)               rating score for indexes
8. resource value (routing)            tag-document similarity

(2,4) are the same, and (3,7) are the same, which leaves us with six attribute
types. In the end we felt it prudent to merge (6,8) into a single arc-attribute
type, and also merge (2,4,3,7) into a single score type. This leaves us with
four distinct attribute types.

We end up with seven generic type parameters in total, which are all present in
the unified interface to the storage layer (`StoreControl`): `<I>` identity,
`<T>` tag, `<A>` address, `<U>` node-attribute, `<W>` arc-attribute, `<S>`
score, `<Z>` identity-score.

### Closeness

We want to measure the closeness of a seed identity to a subject tag.

We start by looking at existing measures of closeness. One standard definition
for the closeness of a node $v$ in a graph, is the inverse-sum of the geodesic
distances to all other nodes[REF]. This does not work for disconnected graphs
where distances can be infinite; variants that work around this, include using
the sum-inverse[REF] and sum-inverse-exponent[REF] of the distances instead.

We look at this last version more closely; its advantages include having closed
formulas for closeness in simple graphs (stars, lines, etc). The closeness of a
node $v$ in graph $G = (V, E)$ is defined:

$$
C(v_0, G) = \sum_{v \in V \setminus v_0} 2^{-d_G(v_0, v)}
$$

where $d_G(v_0, v)$ is the geodesic distance from $v_0$ to $v$ in $G$.

A rough interpretation for this is how easily one can get from $v_0$ to all the
other parts of the graph as a whole. Hand-waving, this is along the lines of
what we want to use as the "difficulty" of a query - getting from our source
identity to the relevant target documents.

Before we continue, we should make precise exactly what we want to get from,
and what we want to get to. Our search application starts from a seed identity
$z$, and traverses several networks to reach a set of result documents $R$
hopefully relevant to $t$. We can make our "closeness" measure derivation
easier, by considering only one network plane - the indexes network.

We define "source" nodes $V_s$ to be the indexes that are present in $z$'s own
ptable, plus some of indexes present in the ptables of their friends.[^meassr]
We define "target" nodes $V_t$ to be the indexes that hold documents associated
to $t$. This problem is now reduced to finding the "closeness" from $V_s$ to
$V_t$, in the same graph (i.e. the indexes network).

[^meassr]: for our sample data, we select the "personal index" of each friend,
ie. the index produced from the user-producer of that friend, rather than the
group-producers. This reduces the cost of the calculation, whilst keeping the
basic idea of what we want to measure.

We can tweak the above measure to give the closeness of $v_0$ relative to a
subset $V_t$ of the nodes, rather than the entire graph:

$$
C(v_0, V_t) = \sum_{v \in V_t} 2^{-d_G(v_0, v)}
$$

(We leave out the $\setminus v_0$ requirement; this was only added in [REF] so
the closeness of an isolated graph is $0$. Further, $v_0$ is always present
in $V$, so it always removes a constant value; however in our extension below,
this isn't true, and we mustn't make an arbitrary non-constant adjustment.)

We can tweak this further, to give the closeness of a set of nodes $V_s$
relative to $V_t$, rather than a single source node:

$$
C(V_s, V_t) = \sum_{v \in V_t} \sum_{u \in V_s} 2^{-d_G(u, v)} / |V_s|
$$

We have $|V_s|$ as a normalisation factor because we doesn't need to traverse
through all the seed indexes to reach a target index; on the other hand, we
don't use $min_{u \in V_s}$ either, because having more seed indexes will
result in more work, since we can't predict which index is the minimum.

Of course, the above definitions all assume an additive distance relation. So
in our calculations, we first convert probability attributes to entropy ones.

## Results

### Query closeness

[DIAG] iframe table

## Future work

(basically scrape all the [EXTN] tags from the rest of the text)


# Meta

These documents were prepared in [pandoc markdown](http://johnmacfarlane.net/pandoc/).

## Interface

Clicking the arrows next to the menus will toggle the visibility of their
children. Shift-clicking will do this recursively for all descendents at all
levels.


# Unfinished notes

## Optimisation

[MOVE] to appendix

### Data structures

- `ptable`
	- quick partition of `index` vs `tgraph` nodes [$G_s$, $H_s$]
	- optionally order these by their score [possible future use]

- `tgraph`, `index`
	- where applicable:
	- quick lookup of node (and weight)
	- quick lookup of node's out-arcs (and weight) [routing, naming]

- `index`
	- quick partition of tag's to-`index` vs to-document arcs
	- optionally order these by their score [routing]

- $\breveg$
	- same as `tgraph`

- $p_s$, $\breveg$, $\breveG$, $\breveH$
	- might want to make these use CombinedWeight objects instead of a float
	  "weight", which in the future could be expanded to include a variance...

- $\breveT$
	- quick lookup of node (and weight)
	- quick iteration through all nodes [$\breveQ$]
	- quick comparison of nodes by their distance ordering [$\breveP$]
	- quick lookup of node's in-arcs (and weight) [$\breveQ$]

- $\ddotg \in \img \breveG_*$, $\ddoth \in \img \breveH_*$
	- quick lookup of node (and weight)
	- quick iteration through all nodes, arcs [$\breveg$]
	- quick lookup of node`s in-arcs (and weight) [routing, naming]
	- quick lookup of node's out-arcs (and weight) [maybe needed by some
	  scoring modules]
	- quick one-time check that all of a node's out-arcs (and weight) have
	  been retrieved from the network [routing, naming]

- $\breveQ$, $\breveR$
	- quick iteration of all lookups/results [$\breveP$, $\breveh$]
	- an advanced implementation would allow items to be added and dynamically
	  ordered in priority, bypassing the need to have $\breveP$, $\breveh$.

### Retrieval of remote objects

Usually we only need to retrieval part of a `tgraph` or `index`, eg. the weight
of a single node, or its out-arcs.

- eg. for quick "no" answer on lookups of storage objects - bloom filters

### Caching storage objects

- eg. cache commonly-retrieved objects like `ptable`s

The contact layer is independent of any query, so this can be done in the background
at any time. We can cache data for the layers above, which will help to
increase performance for future queries. etc...

[MORE] on incremental updates etc.

### Incremental state updates

- eg. when updating $\breveG$ from $\breveG_*$, we should only need to
  recalculate the parts that are affected by the updated....

## Test networks

### Inter-node properties

- neighbour count (ie. degree) distribution
- neighbour semantic relation distribution

### Intra-node properties

- semantic unity (how "related" its tags are)
- semantic specialty (how "general" its tags are)

### Generation algorithms

- Use network formed by extracted data ("real world")
- Barabási-Albert model (preferential attachment)
  - scale-free
  - not small-world; according to wikipedia:
    - clustering coefficient is power-law, similar to hierarchical networks
    - small-world networks have constant clustering coefficient
- TODO etc. read up on network theory.
- hierarchies
- other structures?

Ideally we want a single algorithm which takes as input, various parameters for
the properties listed in the previous two sections, and outputs a random graph
with those properties.

## Simulation

### Request models

### Network conditions

- perfect conditions
- random failure
- malicious attacks - under the assumptions of "abstract storage network", only
  attacks vs the entire network can occur on the naming / routing planes.
  attacks vs individuals on the social plane is a separate topic, ignore here
	- attacks vs most well-connected nodes
	- MORE


# Removed text


## Introduction

Another issue is the depth and granularity of search topics. Most of us don't
use a search provider for every item of information we need; instead, we often
issue a query that gives us a selection of related sites from all over the web,
then manually browse within these sites to target our needs more precisely. In
addition, some websites have non-public information, or specialist knowledge
that generic search algorithms aren't able to index effectively. In these
cases, central index databases are inadequate.

[...]

Imagine your browser acting like a router; you type in a search query and it
automatically follows links between pages to reach what you want. Of course,
this is a long way off, and it may well be beyond the capabilities of current
hardware and networks, but hopefully this project makes a useful contribution
in that direction.


## Theory

We explored many different ideas before implementation began, and during
implementation we weeded out the ones which seemed to lead nowhere. Afterwards,
surviving ideas were explored further, and simplified or generalised.[^simp]

As such, there are a few aspects of our design which may seem inelegant or
imperfect in the context of the theories described below. Unfortunately, we
didn't have time to go back and refine them; but we have tried to point these
out where relevant. None of these flaws, we think, are serious enough to defeat
the basic purpose of the design that we implemented.

[^simp]: For example, information aggregation was originally only considered
for the naming and routing layers, and was completely ignored for the social
layer. During implementation we realised that trust metrics could not resolve
conflicts between ptable entries, and only afterwards did we formulate the
expression of the general problem.


## Distance relation

A **distance metric** also satisfies $\forall a,b,c \in S : D(a,c) \sqsubseteq
D(a,b) \circ D(c,b)$, ie. _symmetry_ ("forwards backwards are equally long")
and _triangle inequality_ ("direct path is shortest"); we won't consider these
restrictions here.

Note[^addrdm]

[^addrdm]: Note also that it isn't a distance _metric_, as it satisfies neither
symmetry nor the triangle inequality. We were (and still are) unaware of any
theory that comments on if this is a bad thing, from a routing perspective.


## Attributes

A related idea is negative attributes, which would represent a judgement that
the resource is malicious or dangerous in some sense, rather than neutral or
"useless". In a system where it's possible to act aggressively, these weights
could provide information on who to attack (or set up defences against).

It's not clear how this applies to our system, which is a network of data and
so only supports passive traps rather than active attacks. It's also unclear
how probability-based attributes could be extended to work this way. So for
now, we ignore this possibility.[EXTN]


## Project infrastructure

Our repository has a fairly simple layout; we have seperate source directories
for application code and test code, and a source directory for documentation.
We used github to publish and backup our repository.


## Search application - structure

as well as Probability and Entropy classes that ensure their values are restricted
to the correct ranges

