% Appendices
% Ximin Luo

# Bibliography

## Papers

[`78Fre`] L. C. Freeman, _Centrality in social networks: Conceptual
clarification_, **1978**. doi:10.1016/0378-8733(78)90021-7

[`98Br+`] S. Brin, L. Page, _The anatomy of a large-scale hypertextual Web
search engine_, **1998-04**. doi:10.1016/S0169-7552(98)00110-X

[`98Cr+`] F. Crestani, M. Lalmas, C. J. Van Rijsbergen, I. Campbell, _A survey
of probabilistic models in information retrieval_, **1998-12**.
doi:10.1145/299917.299920

[`99Kle`] J. Kleinberg, _The Small-World Phenomenon: An Algorithmic
Perspective_, **1999-10**. doi:10.1145/335305.335325

[`00Cl+`] Ian Clarke, Oscar Sandberg, Brandon Wiley, Theodore W. Hong,
_Freenet: A Distributed Anonymous Information Storage and Retrieval System_,
**2000-12**.

[`01St+`] I. Stoica, R. Morris, D. Karger, M. F. Kaashoek, H. Balakrishnan,
_Chord: A scalable peer-to-peer lookup service for internet applications_,
**2001-08**. doi:http://doi.acm.org/10.1145/383059.383071

[`03Gro`] C. Grothoff, _An Excess-Based Economic Model for Resource Allocation
in Peer-to-Peer Networks_, **2003-03**.

[`04Lev`] R. Levien, _Attack Resistant Trust Metrics_, **2004-07**.

[`04Te+`] C. Tempich, S. Staab, A. Wranik, _REMINDIN': semantic query routing
in peer-to-peer networks_, **2004-05**. doi:10.1145/988672.988759

[`04Cl+`] A. Clauset, M. E. J. Newman, C. Moore, _Finding community structure
in very large networks_, **2004-12**. doi:10.1103/PhysRevE.70.066111

[`05Po+`] P. Pons, M. Latapy, _Computing communities in large networks using
random walks_, 2005-12. arXiv:physics/0512106

[`06Dan`] C. Dangalchev, _Residual closeness in networks_, **2006-06**.
doi:10.1016/j.physa.2005.12.020

[`06He+`] R. Herbirch, T. Graepel, _TrueSkill: A Bayesian Skill Rating System_,
**2006-06**.

[`06Ri+`] J. Risson, T. Moors, _Survey of research towards robust peer-to-peer
networks: Search methods_, **2006-12**. doi:10.1016/j.comnet.2006.02.001

[`07Co+`] E. Cohen, A. Fiat, H. Kaplan, _Associative search in peer to peer
networks: Harnessing latent semantics_, **2007-06**.
doi:10.1016/j.comnet.2006.09.014

[`07Ra+`] U. N. Raghavan, R. Albert, S. Kumara, _Near linear time algorithm to
detect community structures in large-scale networks_, **2007-09**.
doi:10.1103/PhysRevE.76.036106

[`09Da+`] G. Danezis, P. Mittal, _SybilInfer: Detecting Sybil Nodes using
Social Networks_, **2009-02**.

[`10LLK`] C. Lesniewski-Laas, M. F. Kaashoek, _Whānau: A Sybil-proof
Distributed Hash Table_, **2010-04**.

## Websites

[`wAdv`] Advogato. http://www.advogato.com/ (see also [`04Lev`])

[`wDel`] Delicious. http://delicious.com/

[`wDOT`] The DOT Language. http://www.graphviz.org/doc/info/lang.html

[`wFkA`] Flickr: API Documentation. http://www.flickr.com/services/api/

[`wFlr`] Flickr. http://www.flickr.com/

[`wFre`] The Freenet Project. http://www.freenetproject.org/ (see also [`00Cl+`])

[`wGIL`] Python documentation: Thread State and the Global Interpreter Lock. http://docs.python.org/c-api/init.html#thread-state-and-the-global-interpreter-lock

[`wGit`] Git. Fast Version Control System. http://git-scm.com/

[`wGnN`] GNUnet. http://www.gnunet.org/ (see also [`03Gro`])

[`wGOM`] The Git Object Model. http://book.git-scm.com/1_the_git_object_model.html

[`wGrM`] The GraphML File Format. http://graphml.graphdrawing.org/

[`wGtl`] Gnutella Protocol Specification. http://wiki.limewire.org/index.php?title=GDF

[`wGvi`] Graphviz: Graph Visualization Software. http://www.graphviz.org/

[`wiGr`] The igraph library for complex network research. http://igraph.sourceforge.net/

[`wJCo`] The Java Tutorials: Collections. http://java.sun.com/docs/books/tutorial/collections/index.html

[`wJEx`] The Java Tutorials: Executor interfaces. http://java.sun.com/docs/books/tutorial/essential/concurrency/exinter.html

[`wJNG`] JUNG: Java Universal Network/Graph Framework. http://jung.sourceforge.net/

[`wLfm`] last.fm. http://www.last.fm/

[`wOSw`] OneSwarm: Privacy preserving P2P. http://oneswarm.cs.washington.edu/

[`wPFk`] Python Flickr API kit. http://stuvel.eu/projects/flickrapi

[`wPFu`] A futures implementation for Python. http://code.google.com/p/pythonfutures/

[`wTru`] TrueSkill. http://research.microsoft.com/en-us/projects/trueskill/default.aspx (see also [`06He+`])

[`wTwi`] Twisted. http://twistedmatrix.com/trac/


# Appendices

## Glossary

arc
:	A directed relation $e = (v_s, v_t)$ from node $v_s$ to node $v_t$.
degree, in-degree, out-degree (of a node-set $V$)
:	See "neighbour (of a node-set $V$)". the \*-degree is just the number of
	\*-neighbours
document
:	A storage object that can be the target of some query. This could include
	(eg.) multimedia or software; for simplicity, we'll refer to these all as
	"document".
identity
:	A node ("user") on the social network
independent union (of a set of probabilities $P$)
:	The probability of at least one event in $P$, assuming all the events are
	independent, given by $1 - \prod_{p \in P} (1 - p)$.
local view
:	For a remote object $x$, the local view holds the parts of $x$ that have
	been retrieved from the network, ie. data that is immediately available to
	the local system. It can distinguish between items found not to exist in
	$x$, and items not yet loaded.
neighbour, in-node, out-node (of a node $v$)
:	A node separated from $v$ by a single arc. We abbreviate "in-neighbour",
	"out-neighbour" to just "in-node", "out-node". We denote the set of all
	neighbours, in-nodes, out-nodes, of $v$ as $\nbrv$, $\predv$, $\succv$.
neighbour, in-node, out-node (of a node-set $V$)
:	We define $\nbrV = (\bigcup_{v \in V} \nbrv) \setminus V$; and $\predV$,
	$\succV$ similarly.
node
:	In the context of a graph or a network, a unique individual
resource relationship, route
:	We write $p \rightarrow^t p'$ to mean that $p$ points to $p'$ via tag $t$.
	In the relevant contexts (e.g. if $p$, $p'$ are tgraphs / indexes), this
	also means that $p$ defines an arc $(t, p')$ as a resource.
tag
:	A semantic unit used to describe documents in a useful way to end users.

## Notation

Here, we document the notation we use for describing the data structures we
use. All are implicitly finite in size.

Partial function $f \subseteq X \to Y$
:	This is non-standard, but $f : X \to Y$ is ambiguous - existing literature
	uses it to mean both a partial or a total function, depending on author.

### Simple objects

Tuple $X = ( a,b,\ldots )$
:	an ordered container of items, of fixed size
:	- the parentheses may be omitted when the context is clear
Union $U = ( a|b|\ldots )$
:	a container holding a single value of any of the specified types
:	- the parentheses may be omitted when the context is clear
Map $M = \{ x : y \}$
:	a container that maps[^mapfn] $x$ to $y$.
:	- write $y_x$ to mean "the $y$ that	$x$ maps to".
	- let $x \in M$ mean the same thing as $x \in \dom M$.
	- the braces may be omitted when the context is clear
List $L = [ x_i ]_{i}$
:	an ordered container of items, of unfixed size

[^mapfn]: This is equivalent to a partial function: $M = \{ x_i \in X \mapsto
y_i \in Y \}_i$ means the same thing as $M \subseteq X \to Y$; however, the
former is a better description of a static data structure.

### Composite objects

We make heavy use of these container objects:

- maps $V_A : V \to A$ of nodes to their attributes.
- maps $E_A : E \to A$ of arcs to their attributes.

These are used in various combinations to represent graphs, inverted indexes,
etc.

For any set $E \subseteq V_s \times V_t$ of arcs, define:

- $\src E = \{ v_s \in V_s : \exists v_t . (v_s, v_t) \in E \}$ ie. the set
  of nodes that the arcs point from.
- $\dst E = \{ v_t \in V_t : \exists v_s . (v_s, v_t) \in E \}$ ie. the set
  of nodes that the arcs point to.
- $\rft E = \src E \cup \dst E$ ie. the set of nodes that E refers to.

For convenience, let this also apply to arc-attribute maps, ie. $\rft E_A =
\rft E$.

## Derivations

### Ranking results

The aggregated index is a map $E_{\barh}$ of tag-document arcs to attributes.
For all $(t, d) : w$, with $w = P(t|d)$, we want to normalise this to $(t_0, d)
: w'$, where $w' = P(t_0|d)$.

For any tag $t$, let $[t_i]_0^n$ be the shortest path from $t_0$ to $t$, where
$t = t_n$. From the address scheme, we have the distance between $t$ and $t_0$:

$$
D(t) = D[t_i]_0^n = \prod_{i=0}^{n-1} P(t_{i+1}|t_i)
$$

If we assume that the pairs $P(t_{i+1}|t_i)$, along with $P(t_n|d)$, are all
independent[^routin] of each other, then we have:

$$
\begin{array}{rl}
D(t)
=& \prod_{i=0}^{n-1} P(t_{i+1}|t_i) \\
=& \prod_{i=0}^{n-1} P(t_{i+1}|t_i, \ldots, t_0) \\
=& P(t_n, \ldots, t_1|t_0) \\
\end{array}
$$

so that:

$$
\begin{array}{rl}
D(t) \frac{P(t_0)}{P(t_n)} P(t_n|d)
=& P(t_n, \ldots, t_1|t_0) \frac{P(t_0)}{P(t_n)} P(t_n|d) \\
=& P(t_{n-1}, \ldots, t_0|t_n) P(t_n|d) \\
=& P(t_n, \ldots, t_0|d) \\
\end{array}
$$

Since $[t_i]$ is the shortest path, we assume that $P(t_n, \ldots, t_0|d)
\approx P(t_0|d)$. So, for each $(t, d) : w$, we have:

$$
w' = D(t) \frac{P(t_0)}{P(t)} w
$$

as an approximation.

[^routin]: This assumption is unlikely to be true, but it's a common assumption
in information retrieval, and appears to give reasonable results.

### Type-parameters

Our design uses several types of objects without making any comment on their
type; these include tags, object addresses (in the storage layer), and social
identities. These are perfect candidates for generic type parameters.

The type of attributes can also be parameterised. Although we use probability
for all of our attributes, this is a part of our specification that is separate
from the overall architecture of the system. A full list of theoretically
distinct types is:

   Source                              Description
-- ----------------------------------- -----------------------------------
1. agent score (social)                social identity trust score
2. resource value (social) (tgraphs)   rating score for tgraphs
3. resource value (social) (indexes)   rating score for indexes
4. agent score (naming)                rating score for tgraphs
5. resource value (naming) (node)      tag size
6. resource value (naming) (arc)       tag-tag similarity
7. agent score (routing)               rating score for indexes
8. resource value (routing)            tag-document similarity

(2,4) are the same, and (3,7) are the same, which leaves us with six attribute
types. In the end we felt it prudent to merge (6,8) into a single arc-attribute
type, and also merge (2,4,3,7) into a single score type. This leaves us with
four distinct attribute types.

We end up with seven generic type parameters in total, which are all present in
the unified interface to the storage layer (`StoreControl`): `<I>` identity,
`<T>` tag, `<A>` address, `<U>` node-attribute, `<W>` arc-attribute, `<S>`
score, `<Z>` identity-score.

### Closeness

We want to measure the closeness of a seed identity to a subject tag.

We start by looking at existing measures of closeness. One standard definition
for the closeness of a node $v$ in a graph, is the inverse-sum of the geodesic
distances to all other nodes [`79Fre`]. This does not work for disconnected
graphs where distances can be infinite; variants that work around this include
using the sum-inverse and sum-inverse-exponent [`06Dan`] of the distances.

We look at this last version more closely; its advantages include having closed
formulas for closeness in simple graphs (stars, lines, etc). The closeness of a
node $v_0$ in graph $G = (V, E)$ is defined:

$$
C(v_0, G) = \sum_{v \in V \setminus v_0} 2^{-d_G(v_0, v)}
$$

where $d_G(v_0, v)$ is the geodesic distance from $v_0$ to $v$ in $G$.

A rough interpretation for this is how easily one can get from $v_0$ to all the
other parts of the graph as a whole. Hand-waving, this is along the lines of
what we want to use as the "difficulty" of a query - getting from our source
identity to the relevant target documents.

Before we continue, we should make precise exactly what we want to get from,
and what we want to get to. Our search application starts from a seed identity
$z$, and traverses several networks to reach a set of result documents $R$
hopefully relevant to $t$. We can make our "closeness" measure derivation
easier, by considering only one network plane - the indexes network.

We define "source" nodes $V_s$ to be the indexes that are present in $z$'s own
ptable, along with some of the indexes[^meassr] present in the ptables of their
friends. We define "target" nodes $V_t$ to be the indexes that hold documents
associated to $t$. This problem is now reduced to finding the "closeness" from
$V_s$ to $V_t$, in the same graph (i.e. the indexes network).

[^meassr]: for our sample data, we select the "personal index" of each friend,
ie. the index produced from the user-producer of that friend, rather than the
group-producers. This reduces the cost of the calculation, whilst keeping the
basic idea of what we want to measure.

We can tweak the above measure to give the closeness of $v_0$ relative to a
subset $V_t$ of the nodes, rather than the entire graph:

$$
C(v_0, V_t) = \sum_{v \in V_t} 2^{-d_G(v_0, v)}
$$

(We leave out the $\setminus v_0$ requirement; this was only added in [`06Dan`]
so the closeness of an isolated graph is $0$. Further, $v_0$ is always present
in $V$, so it always removes a constant value, but in our extension above and
below, this isn't true; we mustn't make an arbitrary non-constant adjustment.)

We can tweak this further, to give the closeness of a set of nodes $V_s$
relative to $V_t$, rather than a single source node:

$$
C(V_s, V_t) = \sum_{v \in V_t} \sum_{u \in V_s} 2^{-d_G(u, v)} / |V_s|
$$

We have $|V_s|$ as a normalisation factor because we doesn't need to traverse
through all the seed indexes to reach a target index; on the other hand, we
don't use $min_{u \in V_s}$ either, because having more seed indexes will
result in more work, since we can't predict which index is the minimum.

Of course, the above definitions all assume an additive distance relation. So
in our calculations, we first convert probability attributes to entropy ones.

<div class="pg-bk-b"></div>
## Results

### Query closeness

<iframe src="../stat/closeness.html" width="720" height="800" frameborder="0"></iframe>

## Future work

This section gives an overview of all the potential areas of improvements that
we weren't able to explore in depth during the course of our project. Refer
back to the relevant chapters of a more detailed discussion of each topic.

Theory

:	1. Review the [address space](design.html#address-space) model, including
	   the problem of the triple intersection.

	2. Explore the cost of trying to [reach](intro.html#objectives) all
	   relevant documents

Architecture

:	1. Make the [layers](design.html#architecture) run fully concurrently, each
	   with their own independent start/pause control.

Trust and authentication

:	1. Make the [contact layer](design.html#contact) use a better trust metric,
	   and hook up a working traversal algorithm for it.

	2. Develop the [score-inferer](design.html#score-inferer) further: theory
	   of its objectives, an attack model, and a test framework.

Information aggregation

:	1. Explore the use of belief distributions instead of probabilities in the
	   [value composer](design.html#value-composer).

	2. Explore more sophisticated algorithms that (e.g.) model implicit
	   expectations for data, or use metadata as part of the valuation.

Evaluation

:	1. Develop a better [sample generator](evaluate.html#processing), that
	   assigns far less seeds to each identity and maybe instead moves this
	   information into the personal producer.

	2. Explore other ways to measure the [difficulty of a
	   query](evaluate.html#query-difficulty)


# Project Proposal

# Meta

These documents were prepared in [pandoc markdown](http://johnmacfarlane.net/pandoc/).

## Interface

Clicking the arrows next to the menus will toggle the visibility of their
children. Shift-clicking will do this recursively for all descendents at all
levels.


# Unfinished notes

## Optimisation

### Data structures

- `ptable`
	- quick partition of `index` vs `tgraph` nodes [$G_s$, $H_s$]
	- optionally order these by their score [possible future use]

- `tgraph`, `index`
	- where applicable:
	- quick lookup of node (and weight)
	- quick lookup of node's out-arcs (and weight) [routing, naming]

- `index`
	- quick partition of tag's to-`index` vs to-document arcs
	- optionally order these by their score [routing]

- $\breveg$
	- same as `tgraph`

- $p_s$, $\breveg$, $\breveG$, $\breveH$
	- might want to make these use CombinedWeight objects instead of a float
	  "weight", which in the future could be expanded to include a variance...

- $\breveT$
	- quick lookup of node (and weight)
	- quick iteration through all nodes [$\breveQ$]
	- quick comparison of nodes by their distance ordering [$\breveP$]
	- quick lookup of node's in-arcs (and weight) [$\breveQ$]

- $\ddotg \in \img \breveG_*$, $\ddoth \in \img \breveH_*$
	- quick lookup of node (and weight)
	- quick iteration through all nodes, arcs [$\breveg$]
	- quick lookup of node`s in-arcs (and weight) [routing, naming]
	- quick lookup of node's out-arcs (and weight) [maybe needed by some
	  scoring modules]
	- quick one-time check that all of a node's out-arcs (and weight) have
	  been retrieved from the network [routing, naming]

- $\breveQ$, $\breveR$
	- quick iteration of all lookups/results [$\breveP$, $\breveh$]
	- an advanced implementation would allow items to be added and dynamically
	  ordered in priority, bypassing the need to have $\breveP$, $\breveh$.

### Retrieval of remote objects

Usually we only need to retrieval part of a `tgraph` or `index`, eg. the weight
of a single node, or its out-arcs.

- eg. for quick "no" answer on lookups of storage objects - bloom filters

### Caching storage objects

- eg. cache commonly-retrieved objects like `ptable`s

The contact layer is independent of any query, so this can be done in the background
at any time. We can cache data for the layers above, which will help to
increase performance for future queries. etc...

[MORE] on incremental updates etc.

### Incremental state updates

- eg. when updating $\breveG$ from $\breveG_*$, we should only need to
  recalculate the parts that are affected by the updated....

## Test networks

### Inter-node properties

- neighbour count (ie. degree) distribution
- neighbour semantic relation distribution

### Intra-node properties

- semantic unity (how "related" its tags are)
- semantic specialty (how "general" its tags are)

### Generation algorithms

- Use network formed by extracted data ("real world")
- Barabási-Albert model (preferential attachment)
  - scale-free
  - not small-world; according to wikipedia:
    - clustering coefficient is power-law, similar to hierarchical networks
    - small-world networks have constant clustering coefficient
- TODO etc. read up on network theory.
- hierarchies
- other structures?

Ideally we want a single algorithm which takes as input, various parameters for
the properties listed in the previous two sections, and outputs a random graph
with those properties.

## Simulation

### Request models

### Network conditions

- perfect conditions
- random failure
- malicious attacks - under the assumptions of "abstract storage network", only
  attacks vs the entire network can occur on the naming / routing planes.
  attacks vs individuals on the social plane is a separate topic, ignore here
	- attacks vs most well-connected nodes
	- MORE


# Removed text


## Introduction

Another issue is the depth and granularity of search topics. Most of us don't
use a search provider for every item of information we need; instead, we often
issue a query that gives us a selection of related sites from all over the web,
then manually browse within these sites to target our needs more precisely. In
addition, some websites have non-public information, or specialist knowledge
that generic search algorithms aren't able to index effectively. In these
cases, central index databases are inadequate.

[...]

Imagine your browser acting like a router; you type in a search query and it
automatically follows links between pages to reach what you want. Of course,
this is a long way off, and it may well be beyond the capabilities of current
hardware and networks, but hopefully this project makes a useful contribution
in that direction.


## Theory

We explored many different ideas before implementation began, and during
implementation we weeded out the ones which seemed to lead nowhere. Afterwards,
surviving ideas were explored further, and simplified or generalised.[^simp]

As such, there are a few aspects of our design which may seem inelegant or
imperfect in the context of the theories described below. Unfortunately, we
didn't have time to go back and refine them; but we have tried to point these
out where relevant. None of these flaws, we think, are serious enough to defeat
the basic purpose of the design that we implemented.

[^simp]: For example, information aggregation was originally only considered
for the naming and routing layers, and was completely ignored for the social
layer. During implementation we realised that trust metrics could not resolve
conflicts between ptable entries, and only afterwards did we formulate the
expression of the general problem.


## Distance relation

A **distance metric** also satisfies $\forall a,b,c \in S : D(a,c) \sqsubseteq
D(a,b) \circ D(c,b)$, ie. _symmetry_ ("forwards backwards are equally long")
and _triangle inequality_ ("direct path is shortest"); we won't consider these
restrictions here.

Note[^addrdm]

[^addrdm]: Note also that it isn't a distance _metric_, as it satisfies neither
symmetry nor the triangle inequality. We were (and still are) unaware of any
theory that comments on if this is a bad thing, from a routing perspective.


## Attributes

So far, we haven't discussed what the attributes should actually represent. In
any usage scenario, they should at least satisfy the following properties:

- The attribute should be some well-defined property that can be measured or
  estimated. Any single value of the attribute should mean the same thing to
  all agents, rather than being left up to agents' own interpretation.
- Attribute values should not be treated as authoritative, since in our model
  we only ever receive data from agents, whom we assume to have a limited view
  of the entire network. There will always be inconsistency between different
  agents; the system should account for this.

In the case of perfectly honest agents, it is hoped that inconsistencies will
work to cancel each other out. In the case of a system under attack, this will
not be the case. However, only looking at the received values for attributes
cannot distinguish between an attack and actual value differences; so this must
be detected in some other way. Our project won't present any methods for doing
this, but network structure analysis is a common approach type.

The exact attribute types we use are discussed [elsewhere](#data-structures).
Generally, we use probability-based attributes, which are well-defined and can
be estimated by agents. It also gives a simple way of combining attributes -
multiplication - as well as a simple space of values - $[0, 1]$.[^attrva]

[...]

A related idea is negative attributes, which would represent a judgement that
the resource is malicious or dangerous in some sense, rather than neutral or
"useless". In a system where it's possible to act aggressively, these weights
could provide information on who to attack (or set up defences against).

It's not clear how this applies to our system, which is a network of data and
so only supports passive traps rather than active attacks. It's also unclear
how probability-based attributes could be extended to work this way. So for
now, we ignore this possibility.[EXTN]


## Project infrastructure

Our repository has a fairly simple layout; we have seperate source directories
for application code and test code, and a source directory for documentation.
We used github to publish and backup our repository.


## Search application - structure

as well as Probability and Entropy classes that ensure their values are restricted
to the correct ranges

