<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <title>Evaluation</title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="author" content="Ximin Luo" />
  <meta name="date" content="" />
  <link rel="stylesheet" href="inc/common.css" type="text/css" />
  <script src="inc/LaTeXMathML.js" type="text/javascript"
  ></script
  >
  <script type="text/javascript">
  /*<![CDATA[*/
  
  inc='\u25b9'; dec='\u25bf';
  ina='\u25b8'; dea='\u25be';
  
  function toggleSect(sect) {
  	if (sect.style.display == 'none') {
  		sect.style.display = 'block';
  		sect.parentNode.firstChild.firstChild.nodeValue = dea;
  		return true;
  	} else {
  		sect.style.display = 'none';
  		sect.parentNode.firstChild.firstChild.nodeValue = ina;
  		return false;
  	}
  }
  
  function incSect(sect) {
  	sect.style.display = 'block';
  	sect.parentNode.firstChild.firstChild.nodeValue = dec;
  }
  
  function decSect(sect) {
  	sect.style.display = 'none';
  	sect.parentNode.firstChild.firstChild.nodeValue = inc;
  }
  
  function disableSelection(target){
  	if ('MozUserSelect' in target.style) {
  		target.style.MozUserSelect = "none"
  	} else if ('onselectstart' in target) {
  		target.onselectstart = function() { return false; }
  	} else {
  		target.onmousedown = function(){ return false; }
  	}
  	target.style.cursor = "default";
  }
  
  function getSectDeep(node, lev, list) {
  	if (lev <= 0) { return; }
  	switch (node.nodeName.toLowerCase()) {
  	case 'ul':
  		for (var i=0; i<node.childNodes.length; i++) {
  			getSectDeep(node.childNodes.item(i), lev, list);
  		}
  		break;
  	case 'li':
  		var obj = node.lastChild;
  		if (obj.nodeName.toLowerCase() == 'ul') {
  			list[list.length] = obj;
  			getSectDeep(obj, lev-1, list);
  		}
  		break;
  	}
  }
  
  window.onload = function() {
  	var toc = document.getElementById("TOC");
  	disableSelection(toc);
  
  	var sect = toc.firstChild.getElementsByTagName('ul');
  	for (var i=0; i<sect.length; ++i) {
  		var li = sect[i].parentNode;
  		var obj = document.createElement('span');
  		obj.appendChild(document.createTextNode(inc));
  		obj.className = 'toggle screenonly-inline';
  		obj.onclick = function(event) {
  			var stat = toggleSect(this.parentNode.lastChild);
  			if (!event.shiftKey) { return; }
  
  			var subs = this.parentNode.lastChild.getElementsByTagName('ul');
  			if (stat) {
  				for (var j=0; j<subs.length; ++j) {
  					incSect(subs[j]);
  				}
  			} else {
  				for (var j=0; j<subs.length; ++j) {
  					decSect(subs[j]);
  				}
  			}
  		}
  		obj.onmouseover = function() {
  			this.firstChild.nodeValue = (this.parentNode.lastChild.style.display == 'none')? ina: dea;
  		}
  		obj.onmouseout = function() {
  			this.firstChild.nodeValue = (this.parentNode.lastChild.style.display == 'none')? inc: dec;
  		}
  		sect[i].style.display = 'none';
  		li.insertBefore(obj, li.firstChild);
  	}
  
  	var list = [];
  	getSectDeep(toc.firstChild, 2, list);
  	for (var i=0; i<list.length; ++i) {
  		incSect(list[i]);
  	}
  
  	var line = toc.firstChild.getElementsByTagName('a');
  	for (var i=0; i<line.length; ++i) {
  		ah = line[i]
  		obj = document.createElement('div');
  		obj.appendChild(document.createTextNode(ah.title));
  		obj.className = "pageno";
  		ah.parentNode.insertBefore(obj, ah);
  	}
  
  }
  
  /*]]>*/
  </script>
</head>
<body>
<h1 class="title">Evaluation</h1>
<ul id="mainmenu">
<li><a href="intro.html">introduction</a></li>
<li><a href="design.html">design</a></li>
<li><a href="evaluate.html">evaluation</a></li>
<li><a href="execute.html">execution</a></li>
<li><a href="appendix.html">appendix</a></li>
<li class="aux"><a href="api/index.html">javadoc</a></li>
</ul>
<div id="TOC"
><ul
  ><li
    ><a href="#generating-data"
      >Generating data</a
      ><ul
      ><li
	><a href="#abstract-data-model"
	  >Abstract data model</a
	  ><ul
	  ><li
	    ><a href="#producer"
	      >Producer</a
	      ></li
	    ><li
	    ><a href="#object-production"
	      >Object production</a
	      ></li
	    ></ul
	  ></li
	><li
	><a href="#application"
	  >Application</a
	  ><ul
	  ><li
	    ><a href="#flickr-overview"
	      >Flickr overview</a
	      ></li
	    ><li
	    ><a href="#crawl-strategy"
	      >Crawl strategy</a
	      ></li
	    ><li
	    ><a href="#processing"
	      >Processing</a
	      ></li
	    ></ul
	  ></li
	></ul
      ></li
    ><li
    ><a href="#measurements"
      >Measurements</a
      ><ul
      ><li
	><a href="#address-scheme"
	  >Address scheme</a
	  ></li
	><li
	><a href="#query-results"
	  >Query results</a
	  ><ul
	  ><li
	    ><a href="#results-score"
	      >Results score</a
	      ></li
	    ><li
	    ><a href="#query-rating"
	      >Query rating</a
	      ></li
	    ><li
	    ><a href="#query-steps"
	      >Query steps</a
	      ></li
	    ></ul
	  ></li
	></ul
      ></li
    ></ul
  ></div
>
<div id="generating-data"
><h1
  ><a href="#TOC"
    >Generating data</a
    ></h1
  ><p
  >Since our system is entirely new, there are no existing samples of data which can be directly for its objects. Rather than generate entirely new data from scratch, we decided to collect data from existing resource-sharing services, and process it to fit our data model.</p
  ><p
  >This has several advantages. It saves us from having to develop a model of how agents interact with regards to resources, which is hard to emulate well. It also helps us to make a crude evaluation on well the system is working - much of the theory depends upon concepts like tag “size” and tag-tag “similarity”, which we will have intuitive expectations for if the tags are real phrases, but not if they are randomly generated data.</p
  ><div id="abstract-data-model"
  ><h2
    ><a href="#TOC"
      >Abstract data model</a
      ></h2
    ><p
    >We assume the following environment:</p
    ><ul
    ><li
      >We have a world-set of documents <span class="LaTeX"
	>$D$</span
	>, and a world-set of tags <span class="LaTeX"
	>$T$</span
	>. Each document has related tags, each associated with an attribute.</li
      ><li
      >We have a social network of identities <span class="LaTeX"
	>$Z$</span
	>. Each identity has some known friends.</li
      ></ul
    ><p
    >We present a framework for generating an index network and a tgraph network on top of this. The model is fairly simple; although we model agents as having limited knowledge of the world, we do not try to model inaccurate or malicious information.</p
    ><div id="producer"
    ><h3
      ><a href="#TOC"
	>Producer</a
	></h3
      ><p
      >The basic generative object, we call a <strong
	>producer</strong
	>. Each producer has:</p
      ><ul
      ><li
	>a resource set, representing the documents that it knows about</li
	><li
	>implicitly, a tag set, containing all the tags associated by any of the documents in the resource set</li
	><li
	>arcs to other producers; each arc has a source tag, and an attribute.</li
	></ul
      ><p
      >Producers represent data agents rather than social identities - that is, they can produce indexes and tgraphs. Producers can link together in a <em
	>resource relationship</em
	>, or <em
	>route</em
	>; we write <span class="LaTeX"
	>$p_0 \rightarrow^t p$</span
	> to mean that <span class="LaTeX"
	>$p_0$</span
	> points to <span class="LaTeX"
	>$p$</span
	> via a tag <span class="LaTeX"
	>$t$</span
	>. (Note again this is <em
	>not</em
	> equivalent to a social relationship.)</p
      ><p
      >Each route <span class="LaTeX"
	>$p_0 \rightarrow^t p$</span
	> has an associated attribute <span class="LaTeX"
	>$w$</span
	>, indicating the similarity of <span class="LaTeX"
	>$t$</span
	> to <span class="LaTeX"
	>$p$</span
	>. For simplicity’s sake, we only calculate <span class="LaTeX"
	>$w$</span
	> given <span class="LaTeX"
	>$t$</span
	> and <span class="LaTeX"
	>$p$</span
	>, and ignore <span class="LaTeX"
	>$p_0$</span
	>. From our specification, any arc <span class="LaTeX"
	>$(t, d)$</span
	> should have attribute <span class="LaTeX"
	>$w = P(t|d)$</span
	>. So given a <span class="LaTeX"
	>$(t, p)$</span
	>, we consider <span class="LaTeX"
	>$p$</span
	> as a set of documents (its resource set) and calculate <span class="LaTeX"
	>$w$</span
	> to be the independent union of <span class="LaTeX"
	>$P(t|d)$</span
	> over <span class="LaTeX"
	>$d \in p$</span
	>.</p
      ></div
    ><div id="object-production"
    ><h3
      ><a href="#TOC"
	>Object production</a
	></h3
      ><p
      >To generate an index, we simply construct an inverted index from tags to the resource set of <span class="LaTeX"
	>$p$</span
	>. Attributes for tag-document arcs are taken from the working environment, as per our assumptions. Attributes for tag-index arcs are taken from the similarity scores for the index’s producer, as calculated above.</p
      ><p
      >Generating a tgraph is more complex; we first construct an estimate <span class="LaTeX"
	>$|\breveD|$</span
	> of <span class="LaTeX"
	>$|D|$</span
	> from the view of a source producer <span class="LaTeX"
	>$p_0$</span
	>. One approach is to take the independent union of <span class="LaTeX"
	>$P(p) = |p|/|D|$</span
	> over <span class="LaTeX"
	>$p \in succ(p_0) \cup p_0$</span
	>. The resource sets of neighbouring producers should be positively correlated, so this will give a size that is larger than the actual union of their resource sets. This is intended to give a result close to what real producers would estimate the network size to be (from their own view).</p
      ><p
      >We then calculate tag sizes and tag-tag similarities by counting the relevant sets of documents and normalising by the appropriate factor. We can calculate sizes for neighbour tgraphs by counting the resource set of its producer and normalising; and tag-producer similarities we already have. Finally, most tags are unrelated, so if a similarity for a particular relation is low then we just ignore this altogether and skip adding the arc to the resulting tgraph.</p
      ></div
    ></div
  ><div id="application"
  ><h2
    ><a href="#TOC"
      >Application</a
      ></h2
    ><p
    >We were aware of three online services based around social sharing of content: Flickr[REF] (photos), Last.fm[REF] (music), and Delicious[REF] (bookmarks). We briefly investigated each of their APIs to see which would be most suitable to base our test data on.</p
    ><p
    >Both Last.fm and Flickr have well-documented APIs; the Delicious API is still under development. Crucially, Flickr groups can hold resources. Last.fm groups only displays stats for members, and Delicious had no API support for groups at the time of writing. Therefore, we decided to use Flickr.</p
    ><div id="flickr-overview"
    ><h3
      ><a href="#TOC"
	>Flickr overview</a
	></h3
      ><p
      >Flickr is an online content-sharing service. As with any social networking service, users can add other users as contacts. On Flickr, this does not need to be reciprocated.</p
      ><p
      >The basic shareable resource on Flickr is a photograph. User can upload their own photos and associate tags to them. They can also add other users’ photos as personal favorites.</p
      ><p
      >Users can create and join common-interest groups. Each group has a group pool to hold photos specific to that interest, which members can post to.</p
      ><p
      >Flickr also infers tag <em
	>clusters</em
	>, which are sets of tags that occur frequently among common photos. (They seem to use an algorithm which infers each cluster from a seed tag-triple.) A tag may belong to more than one cluster; this often corresponds to its different semantic senses. We do not add this cluster data directly to producers, but we use it to generate routes.</p
      ></div
    ><div id="crawl-strategy"
    ><h3
      ><a href="#TOC"
	>Crawl strategy</a
	></h3
      ><p
      >We don’t have enough time or resources to crawl the entire data set of Flickr, so we need to take a coherent and self-contained subset of it.</p
      ><p
      >We start with a single seed user, then perform breath-first search on the social network (outgoing contacts), stopping when a predefined number of users have been met. We then retrieve the groups for each user.</p
      ><p
      >For every user and every group, we create a producer and construct its resource set as follows: for user-producers, we add their own photos and favourites; for group-producers, we add photos from its group pool but restricted to the photos uploaded by the users we just crawled.</p
      ><p
      >We then retrieve the tags for each photo, and the clusters for each tag. At this point, we have all the data we need for constructing our test sample.</p
      ></div
    ><div id="processing"
    ><h3
      ><a href="#TOC"
	>Processing</a
	></h3
      ><p
      >We use both user-producers and group-producers to generate indexes. For each producer, we pre-calculate the similarity for each tag in its tag set. We label the tags with the highest similarities as representative tags, or <em
	>rep-tags</em
	>. We also score documents based on which rep-tags are associated with them; the highest-scored are labelled as representative documents, or <em
	>rep-documents</em
	>.</p
      ><p
      >We generate routes as follows: for each producer <span class="LaTeX"
	>$p_0$</span
	> we select producers whose resource sets contain many rep-documents of <span class="LaTeX"
	>$p_0$</span
	>. We call these the <em
	>related producers</em
	>. For each related producer <span class="LaTeX"
	>$p$</span
	>, we infer tags to link to it with, by calculating intersections between the rep-tags of <span class="LaTeX"
	>$p$</span
	>, and each cluster of the rep-tags of <span class="LaTeX"
	>$p_0$</span
	>.</p
      ><p
      >This (arguably convoluted) method is intended to give a wider-ranging and less predictable selection of tags, than merely taking the intersection of the rep-tags of <span class="LaTeX"
	>$p_0$</span
	> and <span class="LaTeX"
	>$p$</span
	>. This was hoped to be “more realistic”, though this is obviously open to considerable debate.</p
      ><p
      >We then produce indexes according to their resource sets and these routes, using the method described <a href="#object-production"
	>previously</a
	>.</p
      ><p
      >Our data set does not have any natural entities that, we believe, can provide an adequate naming service, as tgraphs are supposed to. (None of our other social service candidates had such functionality either.) However, we do have preconceived ideas of the information tgraphs would contain, and how they would be structured. So we generate new producers from the existing producers, for producing tgraphs. Our model aims to satisfy the following properties:</p
      ><ul
      ><li
	>tgraph producers have a larger view of the network (ie. larger resource set) than index producers</li
	><li
	>the size of each view follows a power-law distribution (as for indexes)</li
	><li
	>the views are interest-oriented (as for indexes)</li
	></ul
      ><p
      >We generate super-producers by running community detection algorithms on the indexes network. These were part of the graph library we used, and include label propagation[REF], greedy max-modularity[REF], and walktrap[REF]. Some of these return dendrograms rather than membership sets; we just cut these at various intervals to get multiple membership sets.</p
      ><p
      >Note that this is <em
	>not</em
	> intended to have a deep theoretical basis, and we did not consider the details of each detected algorithm; rather, we only wanted a quick-and-easy way to achieve the properties listed above.</p
      ><p
      >We construct the resource set of each super-producer from the union of those of their child producers. We generate routes in a similar way to our original producers, and produce tgraphs similarly too.</p
      ><p
      >Lastly, we generate ptables. We simply have each user-producer link to the producers for the groups it belongs to (for indexes) and the super-producers that they in turn belong to (for tgraphs). Social relationships between users are taken straight from the unprocessed data set.</p
      ></div
    ></div
  ></div
><div id="measurements"
><h1
  ><a href="#TOC"
    >Measurements</a
    ></h1
  ><p
  ><em
    >We were far behind schedule by the time we finished coding both the search application and the sample generator, and so we had very little time to devise a comprehensive and precise set of tests. What follows is our attempt to derive some specific measurement metrics that might give a meaningful, if extremely rough, idea on the performance of our system, in the limited time we had left.</em
    ></p
  ><p
  ><em
    >The actual execution of these measurements on the results we obtained, are described in <a href="execute.html#full-testing"
      >testing - full testing</a
      >.</em
    ></p
  ><div id="address-scheme"
  ><h2
    ><a href="#TOC"
      >Address scheme</a
      ></h2
    ><p
    >Our search application infers an address scheme from the tgraphs network. We want a way of comparing this against an “ideal” address scheme (as implied by our theoretical model and the actual data sample). We use two different senses of “ideal”:</p
    ><dl
    ><dt
      >Local</dt
      ><dd
      >We calculate the ideal scheme from our crawl data, restricted to only the tags that are part of the subject scheme.</dd
      ><dt
      >World</dt
      ><dd
      >We calculate the ideal scheme from our entire crawl data, limited to the nearest <span class="LaTeX"
	>$n$</span
	> tags, where <span class="LaTeX"
	>$n$</span
	> is the number of tags in the subject scheme.</dd
      ></dl
    ><p
    >In both cases, we score the subject address scheme using the Jaccard index (|intersection| / |union|) over the two edge sets (subject vs ideal), which gives a measure of their similarity (0 is worst, 1 is best).</p
    ></div
  ><div id="query-results"
  ><h2
    ><a href="#TOC"
      >Query results</a
      ></h2
    ><p
    >Given a map of queries to their results <span class="LaTeX"
      >$\{ (z,t) : R \}$</span
      > we want a way of scoring the result, and comparing this against a measurement of how ideally “hard” the query would have been to satisfy.</p
    ><p
    >In terms of plotting a graph, the query rating is our independent variable, and the results score is our dependent variable.</p
    ><div id="results-score"
    ><h3
      ><a href="#TOC"
	>Results score</a
	></h3
      ><p
      >There are a few standard ways of scoring a set of results for a query. Let <span class="LaTeX"
	>$S$</span
	> be the documents associated with tag <span class="LaTeX"
	>$t$</span
	> (which we know from our data sample), and <span class="LaTeX"
	>$R$</span
	> be the results returned by our search application. Then:</p
      ><dl
      ><dt
	>Precision</dt
	><dd
	><span class="LaTeX"
	  >$p = |R \cap S| / |R|$</span
	  ></dd
	><dt
	>Recall</dt
	><dd
	><span class="LaTeX"
	  >$r = |R \cap S| / |S|$</span
	  ></dd
	><dt
	>F1-score</dt
	><dd
	><span class="LaTeX"
	  >$f = 2pr / (p+r) = 2 |R \cap S| / (|S| + |R|)$</span
	  ></dd
	></dl
      ><p
      >It is widely acknowledged that acheiving high <span class="LaTeX"
	>$p$</span
	> <em
	>and</em
	> <span class="LaTeX"
	>$r$</span
	> is hard, so we will consider these separately. <span class="LaTeX"
	>$f$</span
	> is just the harmonic mean of <span class="LaTeX"
	>$p$</span
	> and <span class="LaTeX"
	>$r$</span
	>, which will be high only if both <span class="LaTeX"
	>$p$</span
	> and <span class="LaTeX"
	>$r$</span
	> are high.</p
      ><p
      >There are also ways to evaluate results’ ranking. However, we did not give any special consideration for ranking documents, nor for ranking our sample data. In any case, we didn’t have the time to explore such evaluation metrics;</p
      ></div
    ><div id="query-rating"
    ><h3
      ><a href="#TOC"
	>Query rating</a
	></h3
      ><p
      >As for the “difficulty” of a query, we were not aware of any existing metric that could be neatly applied to our system, with all its network components. So we tried to come up with our own metric.</p
      ><p
      >The “difficulty” can be interpreted as the “closeness” between a seed identity, and the subject tag for a query. This is vague, we need a more specific measure for our tests. We use the following:</p
      ><p
      ><span class="LaTeX"
	>$$
C(V_s, V_t) = \sum_{v \in V_t} \sum_{u \in V_s} 2^{-d_G(u, v)} / |V_s|
$$</span
	></p
      ><p
      >where <span class="LaTeX"
	>$V_s$</span
	>, <span class="LaTeX"
	>$V_t$</span
	> are the sets of indexes we start from and end at; and <span class="LaTeX"
	>$d_G(u, v)$</span
	> is the geodesic distance between two indexes <span class="LaTeX"
	>$u$</span
	>, <span class="LaTeX"
	>$v$</span
	>. For a more detailed discussion, see <a href="appendix.html#closeness"
	>closeness</a
	> in the appendix.</p
      ><p
      >A more sophisticated rating metric might be to calculate the total length of the minimal subgraph which holds all non-redundant paths from <span class="LaTeX"
	>$V_s$</span
	> to <span class="LaTeX"
	>$V_t$</span
	>. However, this would be more complex to calculate efficiently.[EXTN]</p
      ></div
    ><div id="query-steps"
    ><h3
      ><a href="#TOC"
	>Query steps</a
	></h3
      ><p
      >A third variable that we have so far ignored above is the number of steps to run our search application for - recall that there is no termination condition other than what the user says, and beyond that, searching the entire network.</p
      ><p
      >As the number of steps increases, we expect that recall will increase, whereas precision will increase until “near” results are exhausted, then hopefully only decrease slightly. It would be nice to evaluate this more precisely, but we have no time for this.</p
      ><p
      >However, it’s trivial to have the system print out a results report after a given number of steps <span class="LaTeX"
	>$s$</span
	>, then continue and repeat. We will do this for all queries, with <span class="LaTeX"
	>$s \in \{ 16, 32, 64 \}$</span
	>, and plot (results score) vs (query rating) as described above, for the results at each of these steps, and make brief comments on these sets of evaluations.</p
      ></div
    ></div
  ></div
>

</body>
</html>

